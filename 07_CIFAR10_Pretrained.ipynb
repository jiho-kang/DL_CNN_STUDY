{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiho-kang/DL_CNN_STUDY/blob/main/07_CIFAR10_Pretrained.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "iK0ydqygJonN"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iiUoVnK_JonW"
      },
      "cell_type": "markdown",
      "source": [
        "## Keras의 Pretrained 모델 로딩 및 모델 구조 확인. "
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "gZqR8E7PJonh"
      },
      "cell_type": "code",
      "source": [
        "#from tensorflow.keras.applications.vgg16 import VGG16\n",
        "#from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications import VGG16, ResNet50, ResNet50V2, Xception"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrT4WgtiJonn",
        "outputId": "ef86ac12-a004-4269-cd2e-4275a6e3bf30"
      },
      "cell_type": "code",
      "source": [
        "model = VGG16()\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "553467904/553467096 [==============================] - 9s 0us/step\n",
            "553476096/553467096 [==============================] - 9s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 1000)              4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEO0jX7GJonq",
        "outputId": "f498964c-3643-4ba5-cedc-15e66277a3c0"
      },
      "cell_type": "code",
      "source": [
        "model = VGG16(input_shape=(32, 32, 3), include_top=False, weights='imagenet')\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Qp_bjUN_Jonz"
      },
      "cell_type": "markdown",
      "source": [
        "### Keras의 Model 역시 Functional임. "
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwiHoj_jJon5",
        "outputId": "50265ea9-3dd8-47ce-8c27-d7d5bc6dcfd0"
      },
      "cell_type": "code",
      "source": [
        "print('model:', model)\n",
        "print('model output:', model.output)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model: <keras.engine.functional.Functional object at 0x7f7c000b0450>\n",
            "model output: KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 512), dtype=tf.float32, name=None), name='block5_pool/MaxPool:0', description=\"created by layer 'block5_pool'\")\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "SdxozFu-Jon8"
      },
      "cell_type": "markdown",
      "source": [
        "## Pretrained 모델을 기반으로 CIFAR 10 분류 모델 재 생성. "
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "HOJjK53lJon-"
      },
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 32\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam , RMSprop \n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n",
        "\n",
        "# include_top=False로 기존 imagenet용 classifier 층들을 다 제거. weight는 전이학습을 위해 imagenet 학습된 weight를 초기 weight로 사용. \n",
        "#input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "#base_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
        "base_model = VGG16(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False, weights='imagenet')\n",
        "bm_output = base_model.output\n",
        "\n",
        "# base model의 output을 입력으로 CIFAR10용 Classification layer를 재 구성. \n",
        "x = GlobalAveragePooling2D()(bm_output)\n",
        "# x = Dropout(rate=0.5)(x)\n",
        "x = Dense(50, activation='relu')(x)\n",
        "# x = Dropout(rate=0.2)(x)\n",
        "output = Dense(10, activation='softmax')(x)\n",
        "\n",
        "#model = Model(inputs=input_tensor, outputs=output)\n",
        "model = Model(inputs=base_model.input, outputs = output)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p85s3vAdLcd6",
        "outputId": "f4b009e9-c8c0-4b1c-f52b-519aff915cd2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d_1   (None, 512)              0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense (Dense)               (None, 50)                25650     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                510       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,740,848\n",
            "Trainable params: 14,740,848\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "OxlRXkxDJooC"
      },
      "cell_type": "markdown",
      "source": [
        "## 데이터 전처리 및 ImageDataGenerator로 Augmentation 설정하고 학습용, 검증용 Generator 생성"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftR6wMv5JooD",
        "outputId": "521016b9-0cd2-44de-fca7-6d54f7218e23"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import random as python_random\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "# seed 를 설정해서 학습시마다 동일한 결과 유도. 불행히도 의도한 대로 동작하지 않음. \n",
        "def set_random_seed(seed_value):\n",
        "    np.random.seed(seed_value)\n",
        "    python_random.seed(seed_value)\n",
        "    tf.random.set_seed(seed_value)\n",
        "\n",
        "# 0 ~ 1사이값의 float32로 변경하는 함수\n",
        "def get_preprocessed_data(images, labels, scaling=True):\n",
        "    \n",
        "    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n",
        "    if scaling:\n",
        "        images = np.array(images/255.0, dtype=np.float32)\n",
        "    else:\n",
        "        images = np.array(images, dtype=np.float32)\n",
        "        \n",
        "    labels = np.array(labels, dtype=np.float32)\n",
        "    \n",
        "    return images, labels\n",
        "\n",
        "# 0 ~ 1사이값 float32로 변경하는 함수 호출 한 뒤 OHE 적용 \n",
        "def get_preprocessed_ohe(images, labels):\n",
        "    images, labels = get_preprocessed_data(images, labels, scaling=False)\n",
        "    # OHE 적용 \n",
        "    oh_labels = to_categorical(labels)\n",
        "    return images, oh_labels\n",
        "\n",
        "# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \n",
        "def get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n",
        "    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용. \n",
        "    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n",
        "    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n",
        "    \n",
        "    # 학습 데이터를 검증 데이터 세트로 다시 분리\n",
        "    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n",
        "    \n",
        "    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels ) \n",
        "\n",
        "\n",
        "# random seed는 2021로 고정.\n",
        "set_random_seed(2021)\n",
        "# CIFAR10 데이터 재 로딩 및 Scaling/OHE 전처리 적용하여 학습/검증/데이터 세트 생성. \n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n",
        "\n",
        "(tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n",
        "    get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\n",
        "\n",
        "print(tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_oh_labels.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n",
            "170508288/170498071 [==============================] - 6s 0us/step\n",
            "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n",
            "(42500, 32, 32, 3) (42500, 10) (7500, 32, 32, 3) (7500, 10) (10000, 32, 32, 3) (10000, 10)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "vUsbspoJJooF"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_generator = ImageDataGenerator(\n",
        "    # rotation_range=20,\n",
        "    #zoom_range=(0.7, 0.9),\n",
        "    horizontal_flip=True,\n",
        "    #vertical_flip=True,\n",
        "    rescale=1/255.0\n",
        ")\n",
        "valid_generator = ImageDataGenerator(rescale=1/255.0)\n",
        "\n",
        "flow_tr_gen = train_generator.flow(tr_images, tr_oh_labels, batch_size=BATCH_SIZE, shuffle=True)\n",
        "flow_val_gen = valid_generator.flow(val_images, val_oh_labels, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tHVoySSkJooH"
      },
      "cell_type": "markdown",
      "source": [
        "## Keras CNN 모델 생성 함수. "
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "8B85SXsSJooI"
      },
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 32\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "IpjW2-v_JooK"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam , RMSprop \n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n",
        "\n",
        "def create_model(verbose=False):\n",
        "    \n",
        "    input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "    base_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
        "    bm_output = base_model.output\n",
        "\n",
        "    x = GlobalAveragePooling2D()(bm_output)\n",
        "    #x = Dropout(rate=0.5)(x)\n",
        "    x = Dense(50, activation='relu', name='fc1')(x)\n",
        "    #x = Dropout(rate=0.2)(x)\n",
        "    output = Dense(10, activation='softmax', name='output')(x)\n",
        "\n",
        "    model = Model(inputs=input_tensor, outputs=output)\n",
        "    if verbose:\n",
        "        model.summary()\n",
        "        \n",
        "    return model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MD8qnLGpJooM",
        "outputId": "22bc319e-fc83-4e92-d12a-5e940768efd2"
      },
      "cell_type": "code",
      "source": [
        "vgg_model = create_model(verbose=True)\n",
        "vgg_model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 5번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \n",
        "rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min', verbose=1)\n",
        "# 10번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\n",
        "ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d_3   (None, 512)              0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 50)                25650     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                510       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,740,848\n",
            "Trainable params: 14,740,848\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxjSkKK5JooQ",
        "outputId": "0b93f005-eadf-4aaf-c572-bf98d0f1dd8e"
      },
      "cell_type": "code",
      "source": [
        "# steps 횟수를 구하기 위해 학습 데이터의 건수와 검증 데이터의 건수를 구함. steps = ceil(학습 데이터 건수/BATCH_SIZE)\n",
        "tr_data_len = tr_images.shape[0]\n",
        "val_data_len = val_images.shape[0]\n",
        "history = vgg_model.fit(flow_tr_gen, epochs=40, \n",
        "                    steps_per_epoch=int(np.ceil(tr_data_len/BATCH_SIZE)), \n",
        "                    validation_data=flow_val_gen, validation_steps=int(np.ceil(val_data_len/BATCH_SIZE)),\n",
        "                    callbacks=[rlr_cb, ely_cb])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "665/665 [==============================] - 28s 28ms/step - loss: 1.9188 - accuracy: 0.2454 - val_loss: 1.5416 - val_accuracy: 0.3541 - lr: 0.0010\n",
            "Epoch 2/40\n",
            "665/665 [==============================] - 18s 27ms/step - loss: 1.3069 - accuracy: 0.5034 - val_loss: 1.1243 - val_accuracy: 0.5921 - lr: 0.0010\n",
            "Epoch 3/40\n",
            "665/665 [==============================] - 18s 28ms/step - loss: 0.9682 - accuracy: 0.6658 - val_loss: 0.9338 - val_accuracy: 0.6909 - lr: 0.0010\n",
            "Epoch 4/40\n",
            "665/665 [==============================] - 18s 28ms/step - loss: 0.8040 - accuracy: 0.7319 - val_loss: 0.7493 - val_accuracy: 0.7560 - lr: 0.0010\n",
            "Epoch 5/40\n",
            "665/665 [==============================] - 18s 27ms/step - loss: 0.7058 - accuracy: 0.7652 - val_loss: 0.6779 - val_accuracy: 0.7788 - lr: 0.0010\n",
            "Epoch 6/40\n",
            "665/665 [==============================] - 19s 29ms/step - loss: 0.6198 - accuracy: 0.7969 - val_loss: 0.6804 - val_accuracy: 0.7751 - lr: 0.0010\n",
            "Epoch 7/40\n",
            "665/665 [==============================] - 20s 30ms/step - loss: 0.5705 - accuracy: 0.8143 - val_loss: 0.6651 - val_accuracy: 0.7899 - lr: 0.0010\n",
            "Epoch 8/40\n",
            "665/665 [==============================] - 18s 27ms/step - loss: 0.5229 - accuracy: 0.8269 - val_loss: 0.7420 - val_accuracy: 0.7676 - lr: 0.0010\n",
            "Epoch 9/40\n",
            "665/665 [==============================] - 18s 27ms/step - loss: 0.4886 - accuracy: 0.8406 - val_loss: 0.5956 - val_accuracy: 0.8137 - lr: 0.0010\n",
            "Epoch 10/40\n",
            "665/665 [==============================] - 18s 27ms/step - loss: 0.4471 - accuracy: 0.8551 - val_loss: 0.5944 - val_accuracy: 0.8125 - lr: 0.0010\n",
            "Epoch 11/40\n",
            "665/665 [==============================] - 18s 27ms/step - loss: 0.4197 - accuracy: 0.8631 - val_loss: 0.5528 - val_accuracy: 0.8292 - lr: 0.0010\n",
            "Epoch 12/40\n",
            "665/665 [==============================] - 18s 27ms/step - loss: 0.3999 - accuracy: 0.8703 - val_loss: 0.5452 - val_accuracy: 0.8283 - lr: 0.0010\n",
            "Epoch 13/40\n",
            "665/665 [==============================] - 19s 29ms/step - loss: 0.3673 - accuracy: 0.8813 - val_loss: 0.6014 - val_accuracy: 0.8193 - lr: 0.0010\n",
            "Epoch 14/40\n",
            "665/665 [==============================] - 18s 28ms/step - loss: 0.3571 - accuracy: 0.8842 - val_loss: 0.5955 - val_accuracy: 0.8176 - lr: 0.0010\n",
            "Epoch 15/40\n",
            "665/665 [==============================] - 18s 27ms/step - loss: 0.3238 - accuracy: 0.8960 - val_loss: 0.5811 - val_accuracy: 0.8199 - lr: 0.0010\n",
            "Epoch 16/40\n",
            "665/665 [==============================] - 18s 27ms/step - loss: 0.3099 - accuracy: 0.8990 - val_loss: 0.5531 - val_accuracy: 0.8364 - lr: 0.0010\n",
            "Epoch 17/40\n",
            "664/665 [============================>.] - ETA: 0s - loss: 0.3075 - accuracy: 0.9022\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "665/665 [==============================] - 19s 28ms/step - loss: 0.3074 - accuracy: 0.9022 - val_loss: 0.6375 - val_accuracy: 0.8201 - lr: 0.0010\n",
            "Epoch 18/40\n",
            "665/665 [==============================] - 18s 27ms/step - loss: 0.1752 - accuracy: 0.9437 - val_loss: 0.5468 - val_accuracy: 0.8567 - lr: 2.0000e-04\n",
            "Epoch 19/40\n",
            "665/665 [==============================] - 18s 27ms/step - loss: 0.1250 - accuracy: 0.9603 - val_loss: 0.5837 - val_accuracy: 0.8557 - lr: 2.0000e-04\n",
            "Epoch 20/40\n",
            "665/665 [==============================] - 18s 27ms/step - loss: 0.0977 - accuracy: 0.9692 - val_loss: 0.5933 - val_accuracy: 0.8596 - lr: 2.0000e-04\n",
            "Epoch 21/40\n",
            "665/665 [==============================] - 18s 27ms/step - loss: 0.0760 - accuracy: 0.9767 - val_loss: 0.6315 - val_accuracy: 0.8573 - lr: 2.0000e-04\n",
            "Epoch 22/40\n",
            "664/665 [============================>.] - ETA: 0s - loss: 0.0632 - accuracy: 0.9807\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "665/665 [==============================] - 18s 27ms/step - loss: 0.0632 - accuracy: 0.9807 - val_loss: 0.6998 - val_accuracy: 0.8539 - lr: 2.0000e-04\n",
            "Epoch 22: early stopping\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxzRiYe8Joob",
        "outputId": "d216cf94-a9cd-49b5-ec03-4daaa9b5def9"
      },
      "cell_type": "code",
      "source": [
        "test_generator = ImageDataGenerator(rescale=1/255.0)\n",
        "flow_test_gen = test_generator.flow(test_images, test_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\n",
        "vgg_model.evaluate(flow_test_gen)\n",
        "# 우리 데이터가 32*32라서 featuremap이 너무 작아 특성이 너무 함축적이라 성능이 잘 안나온다."
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 2s 11ms/step - loss: 0.7817 - accuracy: 0.8466\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7816972732543945, 0.8465999960899353]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Vxn5ROQKJood",
        "outputId": "5bea32b2-380c-48a6-ae28-022436caf58b"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def show_history(history):\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.yticks(np.arange(0, 1, 0.05))\n",
        "    plt.xticks(np.arange(0, 30, 2))\n",
        "    plt.plot(history.history['accuracy'], label='train')\n",
        "    plt.plot(history.history['val_accuracy'], label='valid')\n",
        "    plt.legend()\n",
        "    \n",
        "show_history(history)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAD4CAYAAADFLW5aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxV9Z3/8dcn+x4SAgQIEED2pSxRcUOrrVut2tqqbXWs2tp22rG1nc7odH7dF6cz02lnpq1dtNZW6lhtrVVxaRUpKiIoArKELUDClkDIQvbc7++Pc5JckhsIcNfk/Xw87uOce77n3Hxu4OZzzznf7/djzjlEREQkcSTFOgARERE5OUreIiIiCUbJW0REJMEoeYuIiCQYJW8REZEEkxLrAHorKipypaWlsQ5DREQkatasWVPjnBsx0P3jLnmXlpayevXqWIchIiISNWa262T212VzERGRBKPkLSIikmCUvEVERBJM3N3zDqW9vZ3KykpaWlpiHUpUZGRkUFJSQmpqaqxDERGROJQQybuyspLc3FxKS0sxs1iHE1HOOQ4dOkRlZSUTJ06MdTgiIhKHEuKyeUtLC8OHDx/0iRvAzBg+fPiQucogIiInLyGSNzAkEneXofReRUTk5CXEZXMREZFo6OgMcLS1k4bWdhpbO2hs6aChtYOGFm+9sbWdxpYOrpk/lskjcmIWp5L3AB05coQlS5bw93//9yd13JVXXsmSJUsYNmxYhCITEZFgzjnqWzo4UN/CgfoW9te1cOhom598/UTc2u4vexJ0Y0sHze2dJ3x9M5g9Nl/JOxEcOXKEn/zkJ32Sd0dHBykp/f8an3nmmUiHJiIyZLS0d1Ld0Mr+oMR8sKGV/XUt7K9v4WB9CwfqW0Mm4SSD3IxUctJTyM1IISc9hcLsNMYXZnU/z0lPJScjhdz0FHK6tgU9z81IJSs1maSk2N7eVPIeoLvvvpvt27czb948UlNTycjIoKCggM2bN1NeXs61117Lnj17aGlp4fOf/zx33HEH0DPda2NjI1dccQXnn38+r776KmPHjuVPf/oTmZmZMX5nIiLxobWjk71HWqisbaKytpl9R5o5UN+TqA/Ut1Db1N7nuLSUJIrzMijOy2D22HzeMyODUXkZjMr3to3KS6coJ52stORB06co4ZL3N/78Dhv31of1NWeOyeNr75913H3uvfdeNmzYwNq1a1m2bBnve9/72LBhQ/dwrgceeIDCwkKam5s588wzue666xg+fPgxr7F161Z+97vf8Ytf/ILrr7+exx9/nJtuuims70VEJF71Ts49S2/9QH3rMfubQVFOOsV5GZQUZLJwQoGfjL3EPCrPa8vPTB00SXmgEi55x4uzzjrrmHHY//3f/80f//hHAPbs2cPWrVv7JO+JEycyb948ABYuXEhFRUXU4hURibSTTc7JScaYYRmUDMti8ZQRlBRkUVKQSUlBJmMLMinOyyAlOWEGRUXVgJK3mV0O/AhIBn7pnLu3V/sE4AFgBHAYuMk5V+m3dQLr/V13O+euPp2AT3SGHC3Z2dnd68uWLeMvf/kLr732GllZWVx00UUhx2mnp6d3rycnJ9Pc3ByVWEVEImFfXTNrdtWyuqKWNbtq2bivns6A624/XnIuKcxiVG66kvMpOmHyNrNk4MfAe4FK4A0ze9I5tzFot/8AHnLO/drMLga+B9zstzU75+aFOe6oy83NpaGhIWRbXV0dBQUFZGVlsXnzZlauXBnl6EREIqsz4Ni8v/6YZF11xDsByUhNYt64YXxq8SQmj8hRco6CgZx5nwVsc87tADCzR4BrgODkPRP4or/+EvBEOIOMB8OHD+e8885j9uzZZGZmMmrUqO62yy+/nPvuu48ZM2Ywbdo0Fi1aFMNIRUROX2NrB2/t7knUb+2u5Wib14N7ZG46ZaUF3Hb+RMomFDBzTB6pStJRNZDkPRbYE/S8Eji71z5vAx/Eu7T+ASDXzIY75w4BGWa2GugA7nXO9UnsZnYHcAfA+PHjT/pNRMuSJUtCbk9PT2fp0qUh27ruaxcVFbFhw4bu7f/4j/8Y9vhERE6Fc46qI94l8K4z68376wk4r9PYtFG5fGDBWMomFLJwQgElBZlDroNYvAlXh7V/BP7XzD4OLAeqgK5BdhOcc1VmNgl40czWO+e2Bx/snPs58HOAsrIyh4iIRNyr22p4eNVu1lTUsr/e66eTlZbM/PHD+NzFUyibUMD88cPIzVCFw3gzkORdBYwLel7ib+vmnNuLd+aNmeUA1znnjvhtVf5yh5ktA+YDxyRvERGJnt2HmvjOMxt57p0DFOWkc87k4ZRNKGDhhAKmF+fqPnUCGEjyfgOYYmYT8ZL2jcBHg3cwsyLgsHMuANyD1/McMysAmpxzrf4+5wHfD2P8IiIyQI2tHfz4pW3c/7edpCQbX75sGrefP5GM1ORYhyYn6YTJ2znXYWafA57DGyr2gHPuHTP7JrDaOfckcBHwPTNzeJfNP+sfPgP4mZkF8CqY3durl7qIiERYIOD4w1tV/Nuzm6luaOWDC8byz5dPZ1ReRqxDk1M0oHvezrlngGd6bftq0PpjwGMhjnsVmHOaMYqIyClas6uWb/75Hd6urGPeuGH8/OaFzB9fEOuw5DRphjURkUFof10L//bsZv74VhUjc9P5wfXv4tp5Y2NeUEPCQ70SIiQnxysVt3fvXj70oQ+F3Oeiiy5i9erV0QxLRAa5lvZO/uevW3n3fyzj6fX7+Ny7z+Clf7yIDy4oUeIeRHTmHWFjxozhscf63FEQEQkr5xxLN+znO09voupIM1fMLuZfrpzBuMKsWIcmEaDkPUB3330348aN47Of9friff3rXyclJYWXXnqJ2tpa2tvb+fa3v80111xzzHEVFRVcddVVbNiwgebmZm699Vbefvttpk+frrnNRSQsNu6t5xt/fofXdx5menEuSz55NudOLop1WBJBiZe8l94N+9efeL+TUTwHrrj3uLvccMMNfOELX+hO3o8++ijPPfccd955J3l5edTU1LBo0SKuvvrqfmce+ulPf0pWVhabNm1i3bp1LFiwILzvQ0SGlEONrfznC+U8smo3+ZmpfPva2dx45jiN0x4ColFV7BbgX/1dv+2c+3WYYo+q+fPnc/DgQfbu3Ut1dTUFBQUUFxdz1113sXz5cpKSkqiqquLAgQMUFxeHfI3ly5dz5513AjB37lzmzp0bzbcgIoNEe2eAh17bxQ//Uk5TWye3nFvKFy6ZSn6WZkIbKiJaVczMCoGvAWWAA9b4x9aecsQnOEOOpA9/+MM89thj7N+/nxtuuIGHH36Y6upq1qxZQ2pqKqWlpSFLgYqIDIRzjpb2AEfbOmhu6+RoWwdNbZ00tXbS5K/XNbfz0GsVbK8+ygVTivjqVTOZMio31qFLlEW6qthlwAvOucP+sS8AlwO/O/3Qo++GG27gk5/8JDU1Nbz88ss8+uijjBw5ktTUVF566SV27dp13OMXL17MkiVLuPjii9mwYQPr1q2LUuQiEi6dAUdzeyfNbd6jqb2je725vZOm3uvtnTR3JeG2niTc1NbJ0dYOmts7Odrq79PeiRtAdYfS4Vncf0sZF08fqQIhQ1REq4r1c+zY3j8gUaqKzZo1i4aGBsaOHcvo0aP52Mc+xvvf/37mzJlDWVkZ06dPP+7xn/nMZ7j11luZMWMGM2bMYOHChVGKXESOpzPgqKxtYuuBRrYebGTrwQYqa5u7E21LWydNfsJu7Qic1GubQUZKMtnpyWSlpZCVluw/UhienUZWWjKZaSlkd21PT+luD943eH1EbjrJGvY1pEWjqtgJJVJVsfXrezrLFRUV8dprr4Xcr7GxEYDS0tLuUqCZmZk88sgjkQ9SREJq7wyw61AT2w42BCXqRnZUNx6TlIvzMhg/PIuRuRlkpiWTlZpMZpr/SE3uTrg96z3bs9KSyUj1kmxmajIZqUk6O5awi2hVMTOrwpv3PPjYZacRr4jICbV2dLKz5mh3gt52sIFtBxvZWXOU9s6e84OSgkymjMzhgilFnDEyp/uRpxKYEuciWlUMr5jJd/3qYgCX+u0iIiE552jtCBxzv7i5LUBTW0fPvWb/fnLLMfeVO9l7pJltBxupOHSUgJ+jkwzGF2ZxxshcLpkxiikjc5gyMpfJI7PJSku80bIiEOGqYs65w2b2LbwvAADf7Oq8drKcc0Pm0pMbSI8VkQTT0t5JxaGj7Kg+yo7qRnZUH6Xi0FEaWjr6JOKTlZpsZKQmMzI3nWnFuVw1dzRnjMplysgcJhZlq+SlDDoWb4mirKzM9Z7ve+fOneTm5jJ8+PBBn8Cdcxw6dIiGhgYmTpwY63BETopzjv31Ld0Jenv1UXbUeOtVR5qP6UldnJdBaVEWBVlp3r3hfu4tB98/Pvaec8/zVE1KIgnOzNY458oGun9CXDMqKSmhsrKS6urqWIcSFRkZGZSUlMQ6DJF+NbV1eAm6pucsekdNIzurj3K0refMOSstmYlF2cwfX8B1C0qYNCKbySO8s+Hs9IT48yMSlxLi05OamqqzUJEocM5R39zBgYYWDtS3cLC+lQMN/rK+hYMNrew90sy+up7JiMxg7LBMJo3IoWxCIZNHZDNpRA6TRmRTnJcx6K+WicRCQiRvETk9XUn5YEMLB4ISsbfsSdIH6ltpCzGOOTcjhZG56YzKy+CcycOZVNSToEuH656ySLQpeYskOOcctU3t7KtrZt+RFm9Z1+I/vPX9dS0hJxfJTU9hZJ6XlBeOL2BUXgYj8zK6E/WovPTusc4iEj/CVZhkPPBrYJi/z93OuWfMrBTYBGzxd13pnPt0eEIXGfycc9Q1t7P3mKTsL4O29U7MqcnGqLwMRudn8K6SYVw2qychdy/z0jVUaqjrbIdD2717H0kpYEmQlOyvJ3vrluQ9T0r2t3WtH+d2SEcrtDZAaz20Nvrr/qOt4djnoR5t/jHOQUo6pGZ6y5SMEyyPs19qBqTlQlq2/8iB9BxvPTUbkhKr02O4CpP8K/Coc+6nZjYTeAYo9du2O+fmhTdskcHFOUdlbTPrq+pYV1nHO3vrqKr1EnPvoVPJSUZxXgbF+RnMHpvPpbOKKc7LYMywDEbnZzI6P4OinHSSNH2m9KezA9Y/Ci//G9RWnOKLWN+kbgbtTdDZNrDj03P7PvLGQHqel1gtCTpavC8DvZetDdBYHbq9s/Xk305qdk9iT8/xknt3os/t2zblUiiMXV+scBUmcUCev54P7A1nkCKDiXOOqiPNbPAT9foq73GkqR3wzpqnjsplxug8Lp4+kuL8DMYM85Ly6PxMzWstpy7QCRseh2X3wuHtUDwXrv5f78w20Amu01sGOvz1QNB61/ZAr306e451AUjNCp2U03o9T82K3NluIOB9gQhO6O3N0HbUO6vvXvrrrY3HPm876n05aDoMR/b0tLU2eu8TYNj4uE/eAylM8nXgeTP7ByAbeE9Q20QzewuoB/7VOfe33j8gUQqTiJws5xz76lq8BF1Zx7qqOjZU1XH4qHdmkpLkJerLZxUze2w+c0vymVacS3qK7jFLGAUCsPEJL2nXbIFRs+GGh2H6+45/+TtRJSVBkn+pPJyc874MtB31zsJjKFw3vD4CPOic+08zOwf4jZnNBvYB451zh8xsIfCEmc1yztUHH5xIhUlE+uOc40B9K+sqj3hn1X6irmn0EnVykjFlZA7vmTGSOSXDmDM2n+nFueqpLZETCMDmp2DZ9+DgRhgxHT78a5hxdcLd440LZt4XgnB/KTgFYSlMAtyOV6cb59xrZpYBFDnnDgKt/vY1ZrYdmAqsRiSBBQKO3YebeGdvPRv31fHO3nre2VtPdYN3ry3JYOqoXC6aNpK5JfnMHpvPzNF5StQSHc7BlqWw7Luwfz0MnwLX3Q+zPuDdo5aEF5bCJMBu4BLgQTObAWQA1WY2Aq9gSaeZTQKmADvCFr1IFLR1BCg/0MDGffVs3FvPO3vr2LSvgcbWDsC79H2GX5lq7th85pTkM3N0voZXDXWtjVC1Gna/DvvXefdHx53tPXJGRuZnOgdbX4CXvgP71kLBRPjAz2DOh5W0B5lwFSb5EvALM7sLr/Pax51zzswWA980s3YgAHz6VAuTiERDQ0s7m/Y18M5e72x64956th5s6C4jmZWWzIzReXxwwVhmjs5j1ph8pozK0Rm1QF0V7FnpJes9K2H/Br9zk3mJe+vz8Or/ePsWlPqJ/CxvOXLm6SVX52D7i/DSd70vDMPGwzU/hrk3QrKGAw5GCVGYRCTcuu5Pb9rnnUlv3Odd9t51qKl7n6KcNGaOyfeTtPeYMDw7MXp6t7d4Z167X4M9q6DxYNCQnuQQY3ZDjeVN6rWPf1xKBuSXeAli2ARvPQ7uAUZVoBMObPB+t7tXwp7Xoc7v15uaBWMXwvhFMG4RlJRB5jCvo9O+t71997zuJfmjB71j0nK8/boS+lj/mIHY8bKXtPeshLwSuPDL8K6PQkpaZN67RMTJFiZR8pZBr6GlnfIDDWze38CW/T3Luub27n0mDM8KStL5zByTx8jc9MSZl/voIT8hvOYt977VM9Z2+Bleog10Hn+Yz0CHCHU0e+vBcor9ZD7OX47vldwzo/87CafWBqh8o+esunK1N3QIIHcMjD+755J48RxITj3xazoHR3Z5XwC6EvqBd/zfrcHIGVByZs/rDp98bM/wile8jmgVf4Pc0XDBl2DB33mTkkjCUfKWIau9M8CO6qNs3l/PlqBEXXWkuXufnPQUpo7KYVpxHtOLc5lenMuMMXnkZQzgj228cM6bFWvPSu+sb/dKOLTVa0tKhTHzvWQy/hzvj352UXh/fmcHNOyDI7u9R90eLwl1P6/0kn2w7JG9krr/yB/nDblJSfcSXnKa9+ia8CNSnPPHAPczAUhHCzQc8JPqyp6kakkwcpafrBd5y/xx4Yu1tQGq1sCeN7yfXbkKWuq8tqzhUHIWlCyEihWwYxnkjILzvwgLPz70rn4MMkreMuh1jZ3evL+++yx6y/4Gtlc3dt+bTkkyJo3I7k7S00blMq04l5KCzMQ5m+7S0eZdbu06q969EppqvLaMYV6CHr/Ie4yZH/uz3EAnNOzvSeZHdnvJvW6Pv74HAu0nfp3kNEjuldSTU/sm+uD17qTcT0I+2Rm4jrmcfbZ3JpyRd+LjwiUQgJpy/0uEf4Z+aCtkFcH5d0HZbZCWFb14JGKUvGXQaWztYM2uWlbtPMQbFbVs2ldPQ0vPmd2Y/AymFef2JOriXCaNyI7uRCe7XoW1SwDnnf0mpfTcK07u9fy47f7DBbwhPrtXwt43vYQDXu/h8Yv8hH0OFE1NvPG6gQA07veSeN2enuk0O9v9WbHa/OdB2/o82nsd0+otLXmAc2BnnHjO7Ixh3rjoeOvw1VzrzeGtM+1B5WSTd5z9rxSB2qNtvFFxmFU7D7Oq4jDv7K2nM+BITjJmj8njmnljuhP11FG55GfG8JJ3Sx385euw+gHIyPfmRw50hH70vk98Ikkp3vSVZbf3XKbNHRWRtxFVSUne/NV5Y+g7WaOcUGZBrCOQOBDRqmJ+2z14k7h0Anc6554LX/gyGByob/EStf/YcqABgLSUJOaPG8ZnL5rMWROHM3/8MLLT4+j75uan4ekvQeMBOOdz8O5/Of6UiV2dwAId3mXjro5gne1B2zu9NheAwkkxn4JRROJTRKuK+es3ArOAMcBfzGyqc10zu8tQ45xjz+FmXt95qPvMumt4VnZaMgtLC7l63hjOmljI3JL8+Jzju+EALP0ybPyTN0f0jUtg7IITH5eUBElpgIbwiMjpiXRVsWuAR5xzrcBOM9vmv95rYYhdEoBzjm0HG3k96Mx6f713/3ZYVipnlhZy86IJnDWxkJmj80hJjuP7t87BW7+F57/ijaO+5Ktw7p0DGxYkIhJGka4qNhZY2evYsb1/gKqKDT5tHQGeWb+P+1fsZH2VN9RlZG46Z08azlkTCzl7YiFnjMhJnJrTh3fAnz8PO5fDhPPg/f8NRWfEOioRGaIiXVVsQFRVbPCoPdrGklW7eei1Cg7UtzJ5RDbfvGYWF04dwfjCrNMbptXZ7o1vHjY+esNjOjtg5Y/hpe95Z9hX/RAW3JJ4PbxFZFCJaFWxAR4rg8C2g4088MpO/vBmJS3tAS6YUsS9183lwikjTu3sOtAJNVu9mcL2vukt96/3hkylZMLkd3u1iKdeHv5JSLrsexue/AdvOe198L7/8HtIi4jEVkSrigFPAkvM7Ad4HdamAKvCFLvEmHOOFdtquH/FTpZtqSYtJYkPzBvLbedPZFpx7sm8ENRWeEm66k3Yu9abl7tr+snUbBgzD878hFfAYd9a2PwMbHnGm/Fq3NleIp92pTeF5Olqb4Zl93pFJLKL4PqHvPrHiTa5i4gMWgOapMXMrgR+SE9Vse8EVxXze5X/AsjB67z2T8655/1jvwLcBnQAX3DOLT3ez9IkLXGgfq/3SMuB9BxIz/XW/apHLe2d/GltFQ+sqGDLgQaKctK4eVEpH1s0nqKcAcyrXL/XO5OuerPnrLq51mtLTvPmhh6zwOvBPWa+PxFJr17nznlnxFue8RL5gfXe9hHT/UT+Pu/Yk728vXO5d2/78A6YfzNc+i2NqxWRiNMMa3JqarbCpj/D5qe8uZVDcClZNFkGNe3p1AfScak5FA0fzqgRI0jOyPUSfVqul+zTc/zkn+uNWd73dk/CbtzvvaAle2fSY+b5iXqB9/xUqiHVVsCWpd7Y612vegU1ckfDtCu8RD7xguMXbGiuhRe+Cm8+5M1i9v4fwaQLTz4OEZFToOQtA+Ocl0w3PwWbnoKaLd72MQtgxlXe+OW2Rmht5EBNNW9vq2TP/oNkumYm5zumDIOClFastQFaG7v3paO5/585fErP2fSYBd4ZdiQ6njUd9monb34atv0V2o96XyqmvMdL5FPee2y5xY1/gme+DEdr4Nx/gIvujv384CIypCh5S/86O7ziFpuf8hJb3R7v7Lf0PJj+fu9yc743ki8QcCwrP8j9K3byyrZDZKYm86GFJdx6XimTRuQc/2e0+Qm9tcFL6oFOGDXTmz402tpbYOfL3vvdstSrn5yUAqXne/fIdy73fh/Fc+Hq//GuAoiIRJmStxyrvcUrHbjpz9794ebDXtGFyRfD9Ku8y8pZhd27t7R38vibldy/Yic7qo9SnJfBLeeW8pGzxjEsK8FnBgsEoGq1l8g3P+1VZ0rJgIvu8aY3jbcCFCIyZKgwiUBLvXfZeNOfYdtfvLPf9DyYehnMeD9MvsS7Jx2krqmd36ys4MFXK6hpbGNuST4/unEeV84ZTWo8z3p2MpKSYNxZ3uO93/DGjKdlQ25xrCMTETkp4SpM8l/Au/2nWcBI59wwv60T8LsCs9s5d3U4ApdeGqthy9Pe/esdy7ziFtkjYc6HvXvYpYtDdgTbe6SZ+1fs5HerdtPU1slF00bwqcWTWTSpMPHqXp+scAwrExGJgbAUJnHO3RW0/z8A84Neotk5pxuJkVT+HPz+415d5IJSOPtT3hl2yZl9h1j5tuxv4GfLt/Pk2r044Op3jeGOxZOYMTov5P4iIhI/wlWYJNhHgK+FJzw5obce9mYBK54N1/zY6yXezxmzc45VOw/zs+U7eHHzQTJTk7n5nAncfv5ESgqiNN2oiIictnAVJgHAzCYAE4EXgzZnmNlqvEla7nXOPRHiOBUmOVnOwSs/hL98HSZdBDf81htTHUIg4Hh+4wHue3k7a/ccoTA7jS++dyo3L5pAQXaCd0ITERmCwt1h7UbgsV71uic456rMbBLwopmtd85tDz5IhUlOUiDglaVc+ROYfR1ce1/I+9kt7Z088VYVP1++gx01RxlXmMm3rpnFhxaOIzMtDutki4jIgISrMEmXG4HPBm9wzlX5yx1mtgzvfvj2vofKgHS0wROfgQ2Pwdmfgcu+22cK0Lrmdh5+fRe/eqWC6oZWZo/N438+Mp8rZhfHd71sEREZkHAVJsHMpgMFwGtB2wqAJudcq5kVAecB3w9H4ENSawP8382w4yW45Gtw/l3H3N/eX9fCA6/sZMnru2ls7eCCKUX88IZ5nDt5+ODvOS4iMoScMHk75zrM7HPAc/QUJnknuDCJv+uNwCPu2FlfZgA/M7MAkIR3z7u/jm5yPI3VsOTDsG+d1zFt/k3dTS3tnXzzqY38fvUeOgOOq+Z6Pcdnj43BjGYiIhJxmmEtEdRWwG8+APX74MMPwrTLu5vqW9r5xIOreWPXYW46ewJ3LJ7EuEL1HBcRSSSaYW2w2bcOHv4QdLTCLU96s4P5Dja0cMsDb7DtYAP/feN83v+uMTEMVEREokXJO57t/Bs88lFvCNhtT8LI6d1New43cdP9r3OwvpVf3nImF04dEcNARUQkmpS849U7T8AfPgmFk+CmP3RX+wLYvL+ev7t/Fa0dAR7+5NksGF8Qw0BFRCTaNG4oHr3xS2+60zHz4dalxyTu1RWHuf6+1zCD33/6HCVuEZEhSGfe8cQ5WPY9ePnfYOrl8KFfQVpP57OXNh/kMw+vYXR+Jg/ddpY6pomIDFEDOvM2s8vNbIuZbTOzu0O0/5eZrfUf5WZ2JKjtFjPb6j9uCWfwg0pnBzz1BS9xz78Jbnj4mMT9xFtVfPKh1ZwxMofff/ocJW4RkSEsolXFzKwQr0hJGeCANf6xtWF9F4muvQUevx02PwUXfAku/n/HTL7yq1d28o0/b2TRpEJ+8Xdl5GakxjBYERGJtYGceXdXFXPOtQFdVcX68xHgd/76ZcALzrnDfsJ+Abi83yOHouYj3hjuzU/DFd+HS77anbidc/zg+S18488buXTmKB689SwlbhERiXhVsVDHjg1x3NCsKla/D357HdSUw4fu94qM+DoDjq89uYHfrtzN9WUlfPcDczQvuYiIANGpKnZCQ7KqWO0uePAqaD4MH/s9TH53d1NbR4AvPrqWp9bt41MXTuLuy6drbnIREekW6apiVcBFvY5dNvDwBqnOdnjsVmitg48/DWPmdTc1tXXwqd+s4W9ba7jniul86sLJMQxURETi0UCuw3ZXFTOzNLwE/WTvnUJVFaUZS7gAABmySURBVMMrZnKpmRX4FcYu9bcNbS9+G6rWwNX/c0zirj3axkd/8TqvbKvh+9fNVeIWEZGQIlpVzDl32My+hfcFAOCbzrnD4X0LCWb7i/DKD2HhrTCzp9/f/roWbr7/dXYdbuKnNy3kslnFMQxSRETimaqKRVNjNdx3HmQWwCdf6h7HvaO6kZvvX0Vdczs//7uFnDu5KMaBiohINKmqWLwKBOCJz3hDw27+Y3fiXl9Zx8d/tQqAR+5YpBrcIiJyQkre0fL6T2HbC3Dlf8CoWQC8ur2GOx5aQ35mKr+5/SwmjciJcZAiIpIIlLyjYe9aeOFrMP0qOPMTALy1u5aP/+oNJhRm8Zvbz6Y4PyPGQYqISKJQ8o601kZ47DbIGen1LvfHa//vi9vITU/h0U+dQ0F2WoyDFBGRRBKWwiT+Pteb2UYze8fMlgRt7wwqWtJniNmgt/SfoHYnfPDnkFUIeB3U/rr5IB9bNEGJW0RETlpYCpOY2RTgHuA851ytmY0Meolm59w8hqJ1v4e1D8OF/wyl53dv/tUrFaQlJ3HzogkxDE5ERBJVuAqTfBL4cVe1MOfcwfCGmYAO74Cn7oLx58Dif+refKSpjcfWVHLNvDGMyE2PYYAiIpKoBpK8B1JcZCow1cxeMbOVZhZcOSzDzFb7268N9QPM7A5/n9XV1dUn9QbiUkcbPHY7JCXBB38ByT0XOJas2k1zeye3XzAxhgGKiEgiC1eHtRRgCt485iXAcjOb45w7AkxwzlWZ2STgRTNb75zbHnzwoCtM8tJ3YO+bcP1DMKxnWvi2jgC/frWC888oYnpxXgwDFBGRRDaQM++BFCapBJ50zrU753YC5XjJHOdclb/cgVeUZP5pxhzf+pn+FOCZ9fs4UN/K7efrrFtERE5duAqTPIFfPczMivAuo+/wC5KkB20/D9jIYNVYDX/4FIyYAZd995gm5xy/XLGDSSOyuXDqiBgFKCIig8EJk7dzrgPoKkyyCXi0qzCJmV3t7/YccMjMNgIvAV92zh0CZgCrzextf/u9wb3UB5VAAJ74NLTWw4ce6J7+tMuqnYfZUFXP7edPJClJtblFROTUDeiet3PuGeCZXtu+GrTugC/6j+B9XgXmnH6YCeD1n8K2v8D7/hNGzezTfP+KnQzLSuWD80tiEJyIiAwmA5qkRU5g71s905+W3d6nedeho7yw6QA3nT2BzLTkGAQoIiKDiZL36WptCDn9abBfvVJBSpLxd+doUhYRETl9mtv8dD3zT1BbAbc81T39abC65nYeXb2H988dw8g8FR8REZHTpzPv07HuUXh7iTeDWul5IXf5vzd209TWyW0aHiYiImESjcIkt5jZVv9xS7gCj7nDO+CpL/rTn3455C4dnQEefKWCRZMKmT02P8oBiojIYBXRwiRmVgh8DSgDHLDGP7Y2/G8lio4z/WmwpRv2s7euhW9cMzvKAYqIyGAW6cIklwEvOOcO+20vAJeT6F76tjf96dX/e8z0p8G8SVl2Ujo8i0umjwy5j4iIyKmIdGGSgRybWLb9FV75EZTdBjOv7ne3N3fX8vaeI9ymSVlERCTMIlqYZKAHm9kdwB0A48ePD1NIEdBYDX/8dMjpT3u7f8VO8jJSuG6BJmUREZHwinRhkoEci3Pu5865Mudc2YgRcTzv9wv/r2f609TMfnfbc7iJZzfs56NnTyA7XaPxREQkvCJamARvzvNL/QIlBcCl/rbE09EGm5+GOR8OOf1psAdfrSDJjFvO1aQsIiISfic8LXTOdZhZV2GSZOCBrsIkwGrn3JP0JOmNQCc9hUkws2/hfQEA+KZz7nAk3kjE7XrFO+ueduVxd2toaef/3tjDlXNGMzq//7NzERGRUxXRwiR+2wPAA6cXZhwofxZSMmDSRcfd7f/e2ENjawefuECTsoiISGRohrWBcA62LPUSd69Sn8E6A44HX63gzNIC5pYMi1p4IiIytCh5D8TBTXBkF0w9/hD159/ZT2VtM7drKlQREYkgJe+BKF/qLU+QvH+5YifjCjN578ziKAQlIiJDlZL3QGx5FsbMh7zR/e6yds8R1uyq5dZzJ5KsSVlERCSClLxPpLEaKt+AqVccd7f7V+wkNz2F688MPV2qiIhIuISlqpiZfdzMqs1srf/4RFBbZ9D23uPD49/W5wAH0/q/ZF51pJln1u/jxrPGkaNJWUREJMLCUlXM93/Ouc+FeIlm59y80w81RrYshbyxUDy3310eerUC5xy3nFsavbhERGTICldVscGpvQW2v+h1VLPQ97GPtnawZNVurpgzmpKC/oeRiYiIhEu4qooBXGdm68zsMTMLvvGbYWar/Wpj14b6AWZ2h7/P6urq6oFHH2kVf4P2JpjW//3u36/eQ0NLh4aHiYhI1ISrw9qfgVLn3Fy8mt2/Dmqb4JwrAz4K/NDMJvc+OG4Lk2xZCqnZUHpByObOgONXr1Ywf/wwFowviHJwIiIyVIWlqphz7pBzrtV/+ktgYVBblb/cASwD5p9GvNHjnDcl6uR3Q2pGyF3+uukAuw418YnzJ0U5OBERGcrCUlXMzIIHQF8NbPK3F5hZur9eBJwH9O7oFp/2r4P6quNeMv/lip2MHZbJZbNGRTEwEREZ6sJVVexOM7sa6AAOAx/3D58B/MzMAnhfFO4N0Us9Pm15FjCYclnI5vWVdazaeZivXDmDlGQNlxcRkegJV1Wxe4B7Qhz3KjDnNGOMjS3PQMmZkBP6Hvz9K3aQnZbMDWdpUhYREYkunTKGUr8P9q3td2KW/XUtPLVuH9efOY68jNQoByciIkOdknco5c96y36mRH3otQo6nePWczU8TEREok/JO5TyZ2HYBBg5o09TU1sHD7++m8tmFjN+uCZlERGR6FPy7q2tCXYs83qZh5hV7fE3q6hrbuf2C3TWLSIisRGNwiS3mNlW/3FLOIOPiB3LoKMlZO3uQMDxqxU7mVuST9kETcoiIiKxEdHCJGZWCHwNKAMcsMY/tjYs0UdC+VJIz4MJ5/VpemnLQXbUHOVHN87D+pnrXEREJNIiXZjkMuAF59xhP2G/APRfWzPWAgFvfPcZl0BKWp/m363aTXFeBlfOGR3iYBERkeiIdGGSAR0bN4VJ9r4FRw+G7GXe2tHJK9sOcemsUaRqUhYREYmhaBQmOaG4KUxSvhQsGaa8t0/T6opamts7WTwljgqniIjIkBTpwiQnPDaubFkK4xdBVmGfpuXl1aQmG+dMHh6DwERERHpEtDAJ3nzol/oFSgqAS/1t8efIbjiwIWQvc4CXy6spm1BIdvqAZpQVERGJmIgWJnHOHTazb+F9AQD4pnPucATex+kr979TTLuyT9OB+hY272/gny+fHuWgRERE+opoYRK/7QHggdOIMTq2PAPDz4CiM/o0LS/3OtFdOFX3u0VEJPbUbRqgtQEqVvR7yXz51hpG5KYzY3RulAMTERHpS8kbYPuL0NnmTYnaS2fA8bet1VwwpUgTs4iISFxQ8gavl3nGMBi3qE/T+qo6jjS165K5iIjEDSXvQCdsfR6mXArJfbsALC+vxgwu0PhuERGJE0relW9A0yGY1s/97vJq5ozNpzC773SpIiIisRCWqmJB+11nZs7MyvznpWbWHFRt7L5wBR42W56BpBQ44z19muqa23lrzxFdMhcRkbgStqpiZpYLfB54vddLbHfOzQtTvOG35VmvglhGfp+mV7fV0BlwLFbyFhGROBLOqmLfAv4NaAljfJF1aDvUbAnZyxxg+dZqctNTmDduWJQDExER6V9YqoqZ2QJgnHPu6RDHTzSzt8zsZTO7INQPiFlVsfJnvWWI8d3OOV7eUs25ZwxXFTEREYkrp52VzCwJ+AHwpRDN+4Dxzrn5wBeBJWaW13unmFUV27IURsyAwol9mrZXN7K3roULp46MXjwiIiIDEI6qYrnAbGCZmVUAi4AnzazMOdfqnDsE4JxbA2wHpoYj8NPWXAu7Xu23l/nL5TUALJ5aFM2oRERETui0q4o55+qcc0XOuVLnXCmwErjaObfazEb4Hd4ws0nAFGBH2N/Fqdj2V3CdIQuRgFdFbNKIbEoKsqIcmIiIyPGdMHk75zqArqpim4BHu6qK+ZXEjmcxsM7M1gKPAZ+Om6piW5ZCVhGMXdinqaW9k9d3HNIQMRERiUthqSrWa/tFQeuPA4+fRnyR0dkO216A6VdBUnKf5lU7D9PaEdAQMRERiUtDsxv17tegpa7fIWIvl1eTlpLEoonDoxyYiIjIiQ3N5L3lWUhOg0nvDtm8vLyasycWkpnW96xcREQk1oZe8nbOmxJ14mJIz+nTvPdIM1sPNrJYhUhERCRODb3kXVMOtTtDTswC3lk3oPvdIiIStyJamMTfdo9/3BYzuywcQZ+WLUu95XGmRC3Oy2DqqL5n5SIiIvHghMk7qDDJFcBM4CNmNjPEfn0Kk/j73QjMAi4HftI17jtmyp+F4jmQX9KnqaMzwIqtNSyeWoSZxSA4ERGRE4t0YZJrgEf8mdZ2Atv814uNo4dgz+swNfRZ99uVR6hv6dAlcxERiWuRLkxywmP946NTmGTr8+ACxxkiVkOSwflnaEpUERGJX5EuTDIgUStMUr4UcophdOjy4svLq3nXuGEMy0qLXAwiIiKnKaKFSQZwbPR0tMK2F2HqZZDU923XHm3j7cojGiImIiJxL6KFSfz9bjSzdDObiFeYZFXY38VAVKyAtoZ+C5Gs2FaDc3DhNCVvERGJbyec29w512FmXYVJkoEHugqTAKudc08e59h3zOxRYCPQAXzWOdcZpthPTvmzkJIJky4M2by8vJr8zFTeVTIsyoGJiIicnIgWJvGffwf4zinGFx7OeVOiTroIUjNDNDuWb63m/DOKSE7SEDEREYlvQ2OGtQPvQN3ufnuZbznQwIH6VhZPVS9zERGJf0MjeZf7s6pNDT3Bm6ZEFRGRRDI0kveWZ2HMAsgtDtm8vLyGqaNyGJ3f95K6iIhIvBn8ybvhAFSt7reXeVNbB6t2HtYQMRERSRiDP3lvfc5bTgtdRez1HYdp6wxoiJiIiCSMsFQVM7NPm9l6M1trZiu6CpeYWamZNfvb15rZfeF+Aye05VnIK4FRs0M2v1xeTUZqEmeWFkY5MBERkVNzwqFiQVXF3os3N/kbZvakc25j0G5LnHP3+ftfjTddatep7nbnXOj5SCOtvRm2vwjzPwb9VAlbXl7N2ROHk5Ea22JnIiIiAxWWqmLOufqgp9mAC1+Ip8E5uPx7MO9jIZv3HG5iR81RLlQvcxERSSADmaQlVGWws3vvZGafBb4IpAEXBzVNNLO3gHrgX51zfwtx7B3AHQDjx48fcPAnlJYFZbf227x8q4aIiYhI4glbhzXn3I+dc5OBfwb+1d+8DxjvnJuPl9iXmFleiGOjU1Wsl5e3VDN2WCaTR2RH7WeKiIicrnBUFevtEeBaAOdcq3PukL++BtgOTD21UMOrvTPAq9sPsXjqCKyf++EiIiLx6LSrigGY2ZSgp+8DtvrbR/gd3jCzSXhVxXaEI/DT9dbuIzS2dnChpkQVEZEEE66qYp8zs/cA7UAtcIt/+GLgm2bWDgSATzvnDkfijZysl8sPkpxknHuGkreIiCSWsFQVc859vp/jHgceP50AI2V5eQ0Lxg8jLyM11qGIiIiclME/w1oINY2trK+q05SoIiKSkIZk8l6xtQbQEDEREUlMQzJ5Ly+vpjA7jTlj82MdioiIyEkbcsk7EHAs31rD+WcUkZSkIWIiIpJ4IlqYxG+7xz9ui5ldFs7gT8XGffXUNLbqkrmIiCSsEybvoMIkVwAzgY8EJ2ffEufcHL8AyffxCpPg73cjMAuvUMlPusZ9x0r3lKhTNERMREQSU6QLk1wDPOLPtLYT2Oa/XswsL69mxug8RuZlxDIMERGRUzaQ5B2qMMnY3juZ2WfNbDvemfedJ3nsHWa22sxWV1dXDzT2k9bY2sHqiloWa1Y1ERFJYJEuTDLQY6NSmOS17YfoCDgu1PhuERFJYBEtTHIKx0bU8vJqstKSWVhaEKsQRERETltEC5P4+91oZulmNhGvMMmq0w/71CzfWs05k4aTnhLTPnMiIiKnJaKFSfz9HgU2Ah3AZ51znRF6L8dVUXOUXYeauO28ibH48SIiImET0cIkftt3gO+caoDh0jVE7EKN7xYRkQQ3ZGZYW15ezfjCLEqLsmMdioiIyGkZEsm7rSPAq9sPaYiYiIgMCkMiea/edZimtk4unDoy1qGIiIictiGRvJeX15CSZJwzeXisQxERETltQyJ5v1xezcIJBeSkD6h/noiISFwLV1WxL5rZRjNbZ2Z/NbMJQW2dfrWxtWb2ZO9jI+1gQwub9tVz4TT1MhcRkcHhhKeiQVXF3os3N/kbZvakc25j0G5vAWXOuSYz+wze/OY3+G3NfrWxmPhbeQ0AizUlqoiIDBLhqir2knOuyX+6Em8a1Ljwcnk1RTlpzBydF+tQREREwiJsVcWC3A4sDXqe4VcMW2lm14Y6IFJVxQIBx4ptNSyeMoKkJAvb64qIiMRSWHtwmdlNQBlwYdDmCc65KjObBLxoZuudc9uDj3PO/Rz4OUBZWZkjTBrbOrho2ggun1UcrpcUERGJuYEk7wFVBvPnNv8KcKFzrrVru3Ouyl/uMLNlwHxge+/jIyEvI5UfXB+z2+0iIiIREa6qYvOBnwFXO+cOBm0vMLN0f70IOA+vSImIiIiconBVFft3IAf4vZkB7HbOXQ3MAH5mZgG8Lwr39uqlLiIiIifJnAvbLeawKCsrc6tXr451GCIiIlFjZmucc2UD3X9IzLAmIiIymCh5i4iIJBglbxERkQSj5C0iIpJglLxFREQSTNz1NjezamBXmF+2CKgJ82uGQ7zGBYrtVMRrXKDYTkW8xgWK7VTEa1zgxZbtnBtwBa24S96RYGarT6YLfrTEa1yg2E5FvMYFiu1UxGtcoNhORbzGBacWmy6bi4iIJBglbxERkQQzVJL3z2MdQD/iNS5QbKciXuMCxXYq4jUuUGynIl7jglOIbUjc8xYRERlMhsqZt4iIyKCh5C0iIpJgBnXyNrPLzWyLmW0zs7tjHU8XMxtnZi+Z2UYze8fMPh/rmIKZWbKZvWVmT8U6lmBmNszMHjOzzWa2yczOiXVMXczsLv/fcoOZ/c7MMmIYywNmdtDMNgRtKzSzF8xsq78siJO4/t3/91xnZn80s2HRjqu/2ILavmRmzsyK4ik2M/sH/3f3jpl9Px7iMrN5ZrbSzNaa2WozOyvacflxhPwbG+vPwXHiOunPwaBN3maWDPwYuAKYCXzEzGbGNqpuHcCXnHMzgUXAZ+MoNoDPA5tiHUQIPwKedc5NB95FnMRoZmOBO4Ey59xsvLr3N8YwpAeBy3ttuxv4q3NuCvBX/3m0PUjfuF4AZjvn5gLlwD3RDsr3IH1jw8zGAZcCu6MdUJAH6RWbmb0buAZ4l3NuFvAf8RAX8H3gG865ecBX/eex0N/f2Fh/DvqL66Q/B4M2eQNnAducczucc23AI3j/2WPOObfPOfemv96Al4TGxjYqj5mVAO8DfhnrWIKZWT6wGLgfwDnX5pw7EtuojpECZJpZCpAF7I1VIM655cDhXpuvAX7tr/8auDaqQRE6Lufc8865Dv/pSqAk2nH5cYT6nQH8F/BPQMx69vYT22eAe51zrf4+B+MkLgfk+ev5xOhzcJy/sTH9HPQX16l8DgZz8h4L7Al6XkmcJMhgZlYKzAdej20k3X6I98cqEOtAepkIVAO/8i/p/9LMsmMdFIBzrgrvzGc3sA+oc849H9uo+hjlnNvnr+8HRsUymH7cBiyNdRBdzOwaoMo593asYwlhKnCBmb1uZi+b2ZmxDsj3BeDfzWwP3mciVldSuvX6Gxs3n4Pj/O0f0OdgMCfvuGdmOcDjwBecc/VxEM9VwEHn3JpYxxJCCrAA+Klzbj5wlNhc+u3Dv292Dd4XjDFAtpndFNuo+ue88aFxNUbUzL6Cd0nx4VjHAmBmWcC/4F36jUcpQCHepdcvA4+amcU2JMC7InCXc24ccBf+lbJYOd7f2Fh+DvqL62Q+B4M5eVcB44Kel/jb4oKZpeL94z3snPtDrOPxnQdcbWYVeLcZLjaz38Y2pG6VQKVzrutb6mN4yTwevAfY6Zyrds61A38Azo1xTL0dMLPRAP4y6pdZ+2NmHweuAj7m4mfiicl4X8be9j8PJcCbZlYc06h6VAJ/cJ5VeFfKYtKhrpdb8P7/A/we7/ZlTPTzNzbmn4P+/vaf7OdgMCfvN4ApZjbRzNLwOhA9GeOYAPC/Id8PbHLO/SDW8XRxzt3jnCtxzpXi/b5edM7FxRmkc24/sMfMpvmbLgE2xjCkYLuBRWaW5f/bXkKcdKYL8iTeH1b85Z9iGEs3M7sc7zbN1c65pljH08U5t945N9I5V+p/HiqBBf7/w3jwBPBuADObCqQRHxWz9gIX+usXA1tjEcRx/sbG9HPQX1yn9Dlwzg3aB3AlXs+97cBXYh1PUFzn412uWQes9R9XxjquXjFeBDwV6zh6xTQPWO3/3p4ACmIdU1Bs3wA2AxuA3wDpMYzld3j33tvxks7twHC83rVbgb8AhXES1za8vildn4P74uV31qu9AiiKl9jwkvVv/f9vbwIXx0lc5wNrgLfx7uUujNHvLOTf2Fh/Do4T10l/DjQ9qoiISIIZzJfNRUREBiUlbxERkQSj5C0iIpJglLxFREQSjJK3iIhIglHyFhERSTBK3iIiIgnm/wOjotkeaTuwuQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "7Y_mj-YrJook"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wO9FehDZJoop"
      },
      "cell_type": "markdown",
      "source": [
        "## 지금까지의 로직들을 함수화 "
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "QfbsoYneJoor"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam , RMSprop \n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "\n",
        "import random as python_random\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.applications import Xception\n",
        "\n",
        "# seed 를 설정해서 학습시마다 동일한 결과 유도. 불행히도 의도한 대로 동작하지 않음. \n",
        "def set_random_seed(seed_value):\n",
        "    np.random.seed(seed_value)\n",
        "    python_random.seed(seed_value)\n",
        "    tf.random.set_seed(seed_value)\n",
        "\n",
        "# 0 ~ 1사이값의 float32로 변경하는 함수\n",
        "def get_preprocessed_data(images, labels, scaling=True):\n",
        "    \n",
        "    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n",
        "    if scaling:\n",
        "        images = np.array(images/255.0, dtype=np.float32)\n",
        "    else:\n",
        "        images = np.array(images, dtype=np.float32)\n",
        "        \n",
        "    labels = np.array(labels, dtype=np.float32)\n",
        "    \n",
        "    return images, labels\n",
        "\n",
        "# 0 ~ 1사이값 float32로 변경하는 함수 호출 한 뒤 OHE 적용 \n",
        "def get_preprocessed_ohe(images, labels):\n",
        "    images, labels = get_preprocessed_data(images, labels, scaling=False)\n",
        "    # OHE 적용 \n",
        "    oh_labels = to_categorical(labels)\n",
        "    return images, oh_labels\n",
        "\n",
        "# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \n",
        "def get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n",
        "    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용. \n",
        "    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n",
        "    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n",
        "    \n",
        "    # 학습 데이터를 검증 데이터 세트로 다시 분리\n",
        "    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n",
        "    \n",
        "    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels ) \n",
        "\n",
        "# 입력 image의 크기를 resize 값 만큼 증가. CIFAR10의 이미지가 32x32로 작아서 마지막 feature map의 크기가 1로 되어 모델 성능이 좋지 않음. \n",
        "# 마지막 feature map의 크기를 2로 만들기 위해 size 64로 하여 입력 이미지 크기를 변경. 단 메모리를 크게 소비하므로 64이상은 kernel이 다운됨. \n",
        "def get_resized_images(images, size=64):\n",
        "    image_cnt = images.shape[0]\n",
        "    resized_images = np.zeros((images.shape[0], size, size, 3))\n",
        "    for i in range(image_cnt):\n",
        "        resized_image = cv2.resize(images[i], (size, size))\n",
        "        resized_images[i] = resized_image\n",
        "    \n",
        "    return resized_images\n",
        "\n",
        "def create_model(model_name='vgg16', verbose=False):\n",
        "    \n",
        "    input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "    if model_name == 'vgg16':\n",
        "        base_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
        "    elif model_name == 'resnet50':\n",
        "        base_model = ResNet50V2(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
        "    elif model_name == 'xception':\n",
        "        base_model = Xception(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
        "    \n",
        "    bm_output = base_model.output\n",
        "\n",
        "    x = GlobalAveragePooling2D()(bm_output)\n",
        "    if model_name != 'vgg16':\n",
        "        x = Dropout(rate=0.5)(x)\n",
        "    x = Dense(50, activation='relu', name='fc1')(x)\n",
        "    output = Dense(10, activation='softmax', name='output')(x)\n",
        "\n",
        "    model = Model(inputs=input_tensor, outputs=output)\n",
        "    model.summary()\n",
        "        \n",
        "    return model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "lYgqYzejJoot"
      },
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 32\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "def do_cifar10_train_evaluation(image_size=IMAGE_SIZE, model_name='vgg16'):\n",
        "    set_random_seed(2021)\n",
        "    # CIFAR10 데이터 재 로딩 및 Scaling/OHE 전처리 적용하여 학습/검증/데이터 세트 생성. \n",
        "    (train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "    (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n",
        "        get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\n",
        "    print('데이터 세트 shape:', tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_oh_labels.shape)\n",
        "    \n",
        "    # 만약 image_size가 32보다 크면 이미지 크기 재조정. \n",
        "    if image_size > 32:\n",
        "        tr_images = get_resized_images(tr_images, IMAGE_SIZE)\n",
        "        val_images = get_resized_images(val_images, IMAGE_SIZE)\n",
        "        test_images = get_resized_images(test_images, IMAGE_SIZE)\n",
        "    \n",
        "    # 학습/검증/테스트용 ImageDataGenerator와 flow로 pipeline 생성. \n",
        "    train_generator = ImageDataGenerator(\n",
        "        horizontal_flip=True,\n",
        "        rescale=1/255.0\n",
        "    )\n",
        "    valid_generator = ImageDataGenerator(rescale=1/255.0)\n",
        "    test_generator = ImageDataGenerator(rescale=1/255.0)\n",
        "\n",
        "    flow_tr_gen = train_generator.flow(tr_images, tr_oh_labels, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    flow_val_gen = valid_generator.flow(val_images, val_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    flow_test_gen = train_generator.flow(test_images, test_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    \n",
        "    # model_name 에 따른 모델 생성하고 모델 학습 및 검증 수행. \n",
        "    model = create_model(model_name=model_name, verbose=True)\n",
        "    model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # 5번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \n",
        "    rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min', verbose=1)\n",
        "    # 10번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\n",
        "    ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
        "    \n",
        "    tr_data_len = tr_images.shape[0]\n",
        "    val_data_len = val_images.shape[0]\n",
        "    history = model.fit(flow_tr_gen, epochs=40, \n",
        "                        steps_per_epoch=int(np.ceil(tr_data_len/BATCH_SIZE)), \n",
        "                        validation_data=flow_val_gen, validation_steps=int(np.ceil(val_data_len/BATCH_SIZE)),\n",
        "                        callbacks=[rlr_cb, ely_cb])\n",
        "    # 테스트 데이터 세트로 모델 성능 검증 \n",
        "    evaluation_result = model.evaluate(flow_test_gen)\n",
        "    print('테스트 데이터 세트 evaluation 결과:', evaluation_result)\n",
        "    return history, evaluation_result\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juOsLXMOJoou",
        "outputId": "e905ceef-beda-4ffb-c7fc-537ee018fb31"
      },
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "gc.collect()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiQ_7TQKJoow",
        "outputId": "c7f1832c-fa24-4d22-9588-5e1698ab041d"
      },
      "cell_type": "code",
      "source": [
        "# 만약 image_size를 64로 하려면 반드시 RAM이 여유분이 충분히 있는지 확인\n",
        "history, evaluation_result = do_cifar10_train_evaluation(image_size=64, model_name='xception')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n",
            "170508288/170498071 [==============================] - 3s 0us/step\n",
            "데이터 세트 shape: (42500, 32, 32, 3) (42500, 10) (7500, 32, 32, 3) (7500, 10) (10000, 32, 32, 3) (10000, 10)\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n",
            "83697664/83683744 [==============================] - 1s 0us/step\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " block1_conv1 (Conv2D)          (None, 15, 15, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " block1_conv1_bn (BatchNormaliz  (None, 15, 15, 32)  128         ['block1_conv1[0][0]']           \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " block1_conv1_act (Activation)  (None, 15, 15, 32)   0           ['block1_conv1_bn[0][0]']        \n",
            "                                                                                                  \n",
            " block1_conv2 (Conv2D)          (None, 13, 13, 64)   18432       ['block1_conv1_act[0][0]']       \n",
            "                                                                                                  \n",
            " block1_conv2_bn (BatchNormaliz  (None, 13, 13, 64)  256         ['block1_conv2[0][0]']           \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " block1_conv2_act (Activation)  (None, 13, 13, 64)   0           ['block1_conv2_bn[0][0]']        \n",
            "                                                                                                  \n",
            " block2_sepconv1 (SeparableConv  (None, 13, 13, 128)  8768       ['block1_conv2_act[0][0]']       \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block2_sepconv1_bn (BatchNorma  (None, 13, 13, 128)  512        ['block2_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block2_sepconv2_act (Activatio  (None, 13, 13, 128)  0          ['block2_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block2_sepconv2 (SeparableConv  (None, 13, 13, 128)  17536      ['block2_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block2_sepconv2_bn (BatchNorma  (None, 13, 13, 128)  512        ['block2_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 7, 7, 128)    8192        ['block1_conv2_act[0][0]']       \n",
            "                                                                                                  \n",
            " block2_pool (MaxPooling2D)     (None, 7, 7, 128)    0           ['block2_sepconv2_bn[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 7, 7, 128)   512         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 7, 7, 128)    0           ['block2_pool[0][0]',            \n",
            "                                                                  'batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " block3_sepconv1_act (Activatio  (None, 7, 7, 128)   0           ['add[0][0]']                    \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block3_sepconv1 (SeparableConv  (None, 7, 7, 256)   33920       ['block3_sepconv1_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block3_sepconv1_bn (BatchNorma  (None, 7, 7, 256)   1024        ['block3_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block3_sepconv2_act (Activatio  (None, 7, 7, 256)   0           ['block3_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block3_sepconv2 (SeparableConv  (None, 7, 7, 256)   67840       ['block3_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block3_sepconv2_bn (BatchNorma  (None, 7, 7, 256)   1024        ['block3_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 4, 4, 256)    32768       ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " block3_pool (MaxPooling2D)     (None, 4, 4, 256)    0           ['block3_sepconv2_bn[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 4, 4, 256)   1024        ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 4, 4, 256)    0           ['block3_pool[0][0]',            \n",
            "                                                                  'batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " block4_sepconv1_act (Activatio  (None, 4, 4, 256)   0           ['add_1[0][0]']                  \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block4_sepconv1 (SeparableConv  (None, 4, 4, 728)   188672      ['block4_sepconv1_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block4_sepconv1_bn (BatchNorma  (None, 4, 4, 728)   2912        ['block4_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4_sepconv2_act (Activatio  (None, 4, 4, 728)   0           ['block4_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block4_sepconv2 (SeparableConv  (None, 4, 4, 728)   536536      ['block4_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block4_sepconv2_bn (BatchNorma  (None, 4, 4, 728)   2912        ['block4_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 2, 2, 728)    186368      ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " block4_pool (MaxPooling2D)     (None, 2, 2, 728)    0           ['block4_sepconv2_bn[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 2, 2, 728)   2912        ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 2, 2, 728)    0           ['block4_pool[0][0]',            \n",
            "                                                                  'batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " block5_sepconv1_act (Activatio  (None, 2, 2, 728)   0           ['add_2[0][0]']                  \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block5_sepconv1 (SeparableConv  (None, 2, 2, 728)   536536      ['block5_sepconv1_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block5_sepconv1_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block5_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5_sepconv2_act (Activatio  (None, 2, 2, 728)   0           ['block5_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block5_sepconv2 (SeparableConv  (None, 2, 2, 728)   536536      ['block5_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block5_sepconv2_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block5_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5_sepconv3_act (Activatio  (None, 2, 2, 728)   0           ['block5_sepconv2_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block5_sepconv3 (SeparableConv  (None, 2, 2, 728)   536536      ['block5_sepconv3_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block5_sepconv3_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block5_sepconv3[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 2, 2, 728)    0           ['block5_sepconv3_bn[0][0]',     \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " block6_sepconv1_act (Activatio  (None, 2, 2, 728)   0           ['add_3[0][0]']                  \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block6_sepconv1 (SeparableConv  (None, 2, 2, 728)   536536      ['block6_sepconv1_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6_sepconv1_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block6_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6_sepconv2_act (Activatio  (None, 2, 2, 728)   0           ['block6_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block6_sepconv2 (SeparableConv  (None, 2, 2, 728)   536536      ['block6_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6_sepconv2_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block6_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6_sepconv3_act (Activatio  (None, 2, 2, 728)   0           ['block6_sepconv2_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block6_sepconv3 (SeparableConv  (None, 2, 2, 728)   536536      ['block6_sepconv3_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block6_sepconv3_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block6_sepconv3[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 2, 2, 728)    0           ['block6_sepconv3_bn[0][0]',     \n",
            "                                                                  'add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " block7_sepconv1_act (Activatio  (None, 2, 2, 728)   0           ['add_4[0][0]']                  \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block7_sepconv1 (SeparableConv  (None, 2, 2, 728)   536536      ['block7_sepconv1_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block7_sepconv1_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block7_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block7_sepconv2_act (Activatio  (None, 2, 2, 728)   0           ['block7_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block7_sepconv2 (SeparableConv  (None, 2, 2, 728)   536536      ['block7_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block7_sepconv2_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block7_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block7_sepconv3_act (Activatio  (None, 2, 2, 728)   0           ['block7_sepconv2_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block7_sepconv3 (SeparableConv  (None, 2, 2, 728)   536536      ['block7_sepconv3_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block7_sepconv3_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block7_sepconv3[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 2, 2, 728)    0           ['block7_sepconv3_bn[0][0]',     \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " block8_sepconv1_act (Activatio  (None, 2, 2, 728)   0           ['add_5[0][0]']                  \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block8_sepconv1 (SeparableConv  (None, 2, 2, 728)   536536      ['block8_sepconv1_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block8_sepconv1_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block8_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block8_sepconv2_act (Activatio  (None, 2, 2, 728)   0           ['block8_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block8_sepconv2 (SeparableConv  (None, 2, 2, 728)   536536      ['block8_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block8_sepconv2_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block8_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block8_sepconv3_act (Activatio  (None, 2, 2, 728)   0           ['block8_sepconv2_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block8_sepconv3 (SeparableConv  (None, 2, 2, 728)   536536      ['block8_sepconv3_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block8_sepconv3_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block8_sepconv3[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 2, 2, 728)    0           ['block8_sepconv3_bn[0][0]',     \n",
            "                                                                  'add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " block9_sepconv1_act (Activatio  (None, 2, 2, 728)   0           ['add_6[0][0]']                  \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block9_sepconv1 (SeparableConv  (None, 2, 2, 728)   536536      ['block9_sepconv1_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block9_sepconv1_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block9_sepconv1[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block9_sepconv2_act (Activatio  (None, 2, 2, 728)   0           ['block9_sepconv1_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block9_sepconv2 (SeparableConv  (None, 2, 2, 728)   536536      ['block9_sepconv2_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block9_sepconv2_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block9_sepconv2[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block9_sepconv3_act (Activatio  (None, 2, 2, 728)   0           ['block9_sepconv2_bn[0][0]']     \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " block9_sepconv3 (SeparableConv  (None, 2, 2, 728)   536536      ['block9_sepconv3_act[0][0]']    \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " block9_sepconv3_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block9_sepconv3[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 2, 2, 728)    0           ['block9_sepconv3_bn[0][0]',     \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " block10_sepconv1_act (Activati  (None, 2, 2, 728)   0           ['add_7[0][0]']                  \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block10_sepconv1 (SeparableCon  (None, 2, 2, 728)   536536      ['block10_sepconv1_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block10_sepconv1_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block10_sepconv1[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block10_sepconv2_act (Activati  (None, 2, 2, 728)   0           ['block10_sepconv1_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block10_sepconv2 (SeparableCon  (None, 2, 2, 728)   536536      ['block10_sepconv2_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block10_sepconv2_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block10_sepconv2[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block10_sepconv3_act (Activati  (None, 2, 2, 728)   0           ['block10_sepconv2_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block10_sepconv3 (SeparableCon  (None, 2, 2, 728)   536536      ['block10_sepconv3_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block10_sepconv3_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block10_sepconv3[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 2, 2, 728)    0           ['block10_sepconv3_bn[0][0]',    \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " block11_sepconv1_act (Activati  (None, 2, 2, 728)   0           ['add_8[0][0]']                  \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block11_sepconv1 (SeparableCon  (None, 2, 2, 728)   536536      ['block11_sepconv1_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block11_sepconv1_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block11_sepconv1[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block11_sepconv2_act (Activati  (None, 2, 2, 728)   0           ['block11_sepconv1_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block11_sepconv2 (SeparableCon  (None, 2, 2, 728)   536536      ['block11_sepconv2_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block11_sepconv2_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block11_sepconv2[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block11_sepconv3_act (Activati  (None, 2, 2, 728)   0           ['block11_sepconv2_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block11_sepconv3 (SeparableCon  (None, 2, 2, 728)   536536      ['block11_sepconv3_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block11_sepconv3_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block11_sepconv3[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 2, 2, 728)    0           ['block11_sepconv3_bn[0][0]',    \n",
            "                                                                  'add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " block12_sepconv1_act (Activati  (None, 2, 2, 728)   0           ['add_9[0][0]']                  \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block12_sepconv1 (SeparableCon  (None, 2, 2, 728)   536536      ['block12_sepconv1_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block12_sepconv1_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block12_sepconv1[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block12_sepconv2_act (Activati  (None, 2, 2, 728)   0           ['block12_sepconv1_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block12_sepconv2 (SeparableCon  (None, 2, 2, 728)   536536      ['block12_sepconv2_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block12_sepconv2_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block12_sepconv2[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block12_sepconv3_act (Activati  (None, 2, 2, 728)   0           ['block12_sepconv2_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block12_sepconv3 (SeparableCon  (None, 2, 2, 728)   536536      ['block12_sepconv3_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block12_sepconv3_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block12_sepconv3[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 2, 2, 728)    0           ['block12_sepconv3_bn[0][0]',    \n",
            "                                                                  'add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " block13_sepconv1_act (Activati  (None, 2, 2, 728)   0           ['add_10[0][0]']                 \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block13_sepconv1 (SeparableCon  (None, 2, 2, 728)   536536      ['block13_sepconv1_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block13_sepconv1_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block13_sepconv1[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block13_sepconv2_act (Activati  (None, 2, 2, 728)   0           ['block13_sepconv1_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block13_sepconv2 (SeparableCon  (None, 2, 2, 1024)  752024      ['block13_sepconv2_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block13_sepconv2_bn (BatchNorm  (None, 2, 2, 1024)  4096        ['block13_sepconv2[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 1, 1, 1024)   745472      ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " block13_pool (MaxPooling2D)    (None, 1, 1, 1024)   0           ['block13_sepconv2_bn[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 1, 1, 1024)  4096        ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 1, 1, 1024)   0           ['block13_pool[0][0]',           \n",
            "                                                                  'batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " block14_sepconv1 (SeparableCon  (None, 1, 1, 1536)  1582080     ['add_11[0][0]']                 \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block14_sepconv1_bn (BatchNorm  (None, 1, 1, 1536)  6144        ['block14_sepconv1[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block14_sepconv1_act (Activati  (None, 1, 1, 1536)  0           ['block14_sepconv1_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " block14_sepconv2 (SeparableCon  (None, 1, 1, 2048)  3159552     ['block14_sepconv1_act[0][0]']   \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " block14_sepconv2_bn (BatchNorm  (None, 1, 1, 2048)  8192        ['block14_sepconv2[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block14_sepconv2_act (Activati  (None, 1, 1, 2048)  0           ['block14_sepconv2_bn[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 2048)        0           ['block14_sepconv2_act[0][0]']   \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 2048)         0           ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " fc1 (Dense)                    (None, 50)           102450      ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " output (Dense)                 (None, 10)           510         ['fc1[0][0]']                    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 20,964,440\n",
            "Trainable params: 20,909,912\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "665/665 [==============================] - 63s 75ms/step - loss: 0.7279 - accuracy: 0.7580 - val_loss: 0.7491 - val_accuracy: 0.7645 - lr: 0.0010\n",
            "Epoch 2/40\n",
            "665/665 [==============================] - 49s 73ms/step - loss: 0.3934 - accuracy: 0.8707 - val_loss: 0.5192 - val_accuracy: 0.8604 - lr: 0.0010\n",
            "Epoch 3/40\n",
            "665/665 [==============================] - 49s 73ms/step - loss: 0.3025 - accuracy: 0.9019 - val_loss: 0.3586 - val_accuracy: 0.8880 - lr: 0.0010\n",
            "Epoch 4/40\n",
            "665/665 [==============================] - 49s 73ms/step - loss: 0.2444 - accuracy: 0.9200 - val_loss: 0.6369 - val_accuracy: 0.8160 - lr: 0.0010\n",
            "Epoch 5/40\n",
            "665/665 [==============================] - 49s 73ms/step - loss: 0.2092 - accuracy: 0.9314 - val_loss: 0.3631 - val_accuracy: 0.8871 - lr: 0.0010\n",
            "Epoch 6/40\n",
            "665/665 [==============================] - 49s 74ms/step - loss: 0.1757 - accuracy: 0.9416 - val_loss: 0.3238 - val_accuracy: 0.8968 - lr: 0.0010\n",
            "Epoch 7/40\n",
            "665/665 [==============================] - 49s 74ms/step - loss: 0.1512 - accuracy: 0.9511 - val_loss: 0.3622 - val_accuracy: 0.8907 - lr: 0.0010\n",
            "Epoch 8/40\n",
            "665/665 [==============================] - 49s 73ms/step - loss: 0.1278 - accuracy: 0.9592 - val_loss: 0.4800 - val_accuracy: 0.8708 - lr: 0.0010\n",
            "Epoch 9/40\n",
            "665/665 [==============================] - 49s 74ms/step - loss: 0.1354 - accuracy: 0.9566 - val_loss: 0.3821 - val_accuracy: 0.8867 - lr: 0.0010\n",
            "Epoch 10/40\n",
            "665/665 [==============================] - 49s 73ms/step - loss: 0.1200 - accuracy: 0.9618 - val_loss: 0.6132 - val_accuracy: 0.8327 - lr: 0.0010\n",
            "Epoch 11/40\n",
            "665/665 [==============================] - ETA: 0s - loss: 0.1250 - accuracy: 0.9588\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "665/665 [==============================] - 49s 73ms/step - loss: 0.1250 - accuracy: 0.9588 - val_loss: 0.3593 - val_accuracy: 0.9009 - lr: 0.0010\n",
            "Epoch 12/40\n",
            "665/665 [==============================] - 49s 73ms/step - loss: 0.0418 - accuracy: 0.9870 - val_loss: 0.2395 - val_accuracy: 0.9371 - lr: 2.0000e-04\n",
            "Epoch 13/40\n",
            "665/665 [==============================] - 49s 73ms/step - loss: 0.0213 - accuracy: 0.9932 - val_loss: 0.2360 - val_accuracy: 0.9375 - lr: 2.0000e-04\n",
            "Epoch 14/40\n",
            "665/665 [==============================] - 49s 73ms/step - loss: 0.0120 - accuracy: 0.9965 - val_loss: 0.2666 - val_accuracy: 0.9387 - lr: 2.0000e-04\n",
            "Epoch 15/40\n",
            "665/665 [==============================] - 49s 73ms/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 0.2839 - val_accuracy: 0.9372 - lr: 2.0000e-04\n",
            "Epoch 16/40\n",
            "665/665 [==============================] - 49s 73ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 0.3732 - val_accuracy: 0.9272 - lr: 2.0000e-04\n",
            "Epoch 17/40\n",
            "665/665 [==============================] - 49s 73ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 0.2945 - val_accuracy: 0.9363 - lr: 2.0000e-04\n",
            "Epoch 18/40\n",
            "665/665 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9977\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "665/665 [==============================] - 49s 73ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.2901 - val_accuracy: 0.9401 - lr: 2.0000e-04\n",
            "Epoch 19/40\n",
            "665/665 [==============================] - 49s 73ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.2770 - val_accuracy: 0.9425 - lr: 4.0000e-05\n",
            "Epoch 20/40\n",
            "665/665 [==============================] - 49s 73ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.2782 - val_accuracy: 0.9429 - lr: 4.0000e-05\n",
            "Epoch 21/40\n",
            "665/665 [==============================] - 49s 73ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.2807 - val_accuracy: 0.9432 - lr: 4.0000e-05\n",
            "Epoch 22/40\n",
            "665/665 [==============================] - 49s 73ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.2933 - val_accuracy: 0.9429 - lr: 4.0000e-05\n",
            "Epoch 23/40\n",
            "665/665 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "665/665 [==============================] - 49s 73ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.2940 - val_accuracy: 0.9437 - lr: 4.0000e-05\n",
            "Epoch 23: early stopping\n",
            "157/157 [==============================] - 3s 20ms/step - loss: 0.3505 - accuracy: 0.9339\n",
            "테스트 데이터 세트 evaluation 결과: [0.35047248005867004, 0.933899998664856]\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyQZpr7MJoo1",
        "outputId": "a0958f0f-3669-453a-fa94-e6b36f286e5d"
      },
      "cell_type": "code",
      "source": [
        "print('테스트 데이터세트 검증 결과:', evaluation_result)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터세트 검증 결과: [0.35047248005867004, 0.933899998664856]\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "HPVuD3-2Joo3",
        "outputId": "d4145c6c-e127-407e-e957-3d9a5add70b0"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def show_history(history):\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.yticks(np.arange(0, 1, 0.05))\n",
        "    plt.xticks(np.arange(0, 30, 2))\n",
        "    plt.plot(history.history['accuracy'], label='train')\n",
        "    plt.plot(history.history['val_accuracy'], label='valid')\n",
        "    plt.legend()\n",
        "    \n",
        "show_history(history)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "uYj7ib1fJoo7"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "07-CIFAR10_Pretrained.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}