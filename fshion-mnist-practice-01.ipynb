{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames: \n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-13T23:15:59.496934Z","iopub.execute_input":"2022-02-13T23:15:59.497929Z","iopub.status.idle":"2022-02-13T23:15:59.526124Z","shell.execute_reply.started":"2022-02-13T23:15:59.497805Z","shell.execute_reply":"2022-02-13T23:15:59.525226Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Keras fashion mnist dataset을 다운로드\n* 5만개의 학습용, 1만개의 테스트용 grayscale image array를 다운로드","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.datasets import fashion_mnist\n\n# 전체 6만개 데이터 중, 5만개는 학습 데이터용, 1만개는 테스트 데이터용으로 분리\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n# image size는 28x28의 grayscale 2차원 데이터\nprint(\"train dataset shape:\", train_images.shape, train_labels.shape)\nprint(\"test dataset shape:\", test_images.shape, test_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T23:22:22.633675Z","iopub.execute_input":"2022-02-13T23:22:22.634288Z","iopub.status.idle":"2022-02-13T23:22:23.129268Z","shell.execute_reply.started":"2022-02-13T23:22:22.634237Z","shell.execute_reply":"2022-02-13T23:22:23.128460Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### MNIST image array 시각화","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.imshow(train_images[0], cmap='gray')\nplt.title(train_labels[0])","metadata":{"execution":{"iopub.status.busy":"2022-02-13T23:22:23.131208Z","iopub.execute_input":"2022-02-13T23:22:23.131752Z","iopub.status.idle":"2022-02-13T23:22:23.335113Z","shell.execute_reply.started":"2022-02-13T23:22:23.131708Z","shell.execute_reply":"2022-02-13T23:22:23.334152Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"print(train_images.shape)\nprint(train_images[0, :, :].shape) # 위 신발에 대한 array\n\nprint()\nprint(train_images[0, :, :])\nprint('label:',train_labels[0])","metadata":{"execution":{"iopub.status.busy":"2022-02-13T23:22:23.336495Z","iopub.execute_input":"2022-02-13T23:22:23.336819Z","iopub.status.idle":"2022-02-13T23:22:23.346362Z","shell.execute_reply.started":"2022-02-13T23:22:23.336776Z","shell.execute_reply":"2022-02-13T23:22:23.345467Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline \n\nclass_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n\ndef show_images(images, labels, ncols=8):\n    figure, axs = plt.subplots(figsize=(22, 6), nrows=1, ncols=ncols) # axs는 plot들이다.\n    for i in range(ncols):\n        axs[i].imshow(images[i], cmap='gray')\n        axs[i].set_title(class_names[labels[i]])\n        \nshow_images(train_images[:8], train_labels[:8], ncols=8)\nshow_images(train_images[8:16], train_labels[8:16], ncols=8)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T23:22:23.348205Z","iopub.execute_input":"2022-02-13T23:22:23.348577Z","iopub.status.idle":"2022-02-13T23:22:25.150402Z","shell.execute_reply.started":"2022-02-13T23:22:23.348533Z","shell.execute_reply":"2022-02-13T23:22:25.149637Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### 데이터 전처리 수행. \n* 0 ~ 255 사이의 픽셀값을 0 ~ 1 사이 값으로 변환. \n* array type은 float 32","metadata":{}},{"cell_type":"code","source":"(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n\ndef get_preprocessed_data(images, labels):\n    \n    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n    images = np.array(images/255.0, dtype=np.float32)\n    labels = np.array(labels, dtype=np.float32)\n    \n    return images, labels\n\ntrain_images_preprocessed, train_labels_preprocessed = get_preprocessed_data(train_images, train_labels)\ntest_images_preprocessed, test_labels_preprocessed = get_preprocessed_data(test_images, test_labels)\n\nprint(\"train dataset shape:\", train_images_preprocessed.shape, train_labels_preprocessed.shape)\nprint(\"test dataset shape:\", test_images_preprocessed.shape, test_labels_preprocessed.shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-13T23:30:13.993588Z","iopub.execute_input":"2022-02-13T23:30:13.994172Z","iopub.status.idle":"2022-02-13T23:30:14.739984Z","shell.execute_reply.started":"2022-02-13T23:30:13.994126Z","shell.execute_reply":"2022-02-13T23:30:14.739169Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"train_images[0]","metadata":{"execution":{"iopub.status.busy":"2022-02-13T23:30:14.741387Z","iopub.execute_input":"2022-02-13T23:30:14.741692Z","iopub.status.idle":"2022-02-13T23:30:14.750624Z","shell.execute_reply.started":"2022-02-13T23:30:14.741661Z","shell.execute_reply":"2022-02-13T23:30:14.749823Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"train_images_preprocessed[0]","metadata":{"execution":{"iopub.status.busy":"2022-02-13T23:30:14.751889Z","iopub.execute_input":"2022-02-13T23:30:14.752154Z","iopub.status.idle":"2022-02-13T23:30:14.773434Z","shell.execute_reply.started":"2022-02-13T23:30:14.752123Z","shell.execute_reply":"2022-02-13T23:30:14.772747Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"### Dense Layer를 기반으로 모델을 생성","metadata":{}},{"cell_type":"code","source":"INPUT_SIZE = 28 ","metadata":{"execution":{"iopub.status.busy":"2022-02-13T23:30:14.774840Z","iopub.execute_input":"2022-02-13T23:30:14.775710Z","iopub.status.idle":"2022-02-13T23:30:14.782799Z","shell.execute_reply.started":"2022-02-13T23:30:14.775662Z","shell.execute_reply":"2022-02-13T23:30:14.781991Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.models import Sequential\n\nmodel = Sequential([\n    Flatten(input_shape=(INPUT_SIZE, INPUT_SIZE)),# H*W = 28, 28\n    Dense(100, activation='relu'),\n    Dense(30, activation='relu'),\n    Dense(10, activation='softmax')\n])\n\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2022-02-13T23:30:14.799676Z","iopub.execute_input":"2022-02-13T23:30:14.799996Z","iopub.status.idle":"2022-02-13T23:30:14.842307Z","shell.execute_reply.started":"2022-02-13T23:30:14.799965Z","shell.execute_reply":"2022-02-13T23:30:14.841543Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"### 모델의 Loss와 Optimizer 설정하고 학습 수행\n* loss는 categorical_crossentropy로, optimizer는 Adam으로 설정\n* categorical crossentropy를 위해서 Lable을 OHE 로 변경","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.metrics import Accuracy\n\nmodel.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-02-13T23:30:15.097306Z","iopub.execute_input":"2022-02-13T23:30:15.097574Z","iopub.status.idle":"2022-02-13T23:30:15.107910Z","shell.execute_reply.started":"2022-02-13T23:30:15.097545Z","shell.execute_reply":"2022-02-13T23:30:15.106945Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import OneHotEncoder\n\ntrain_labels_categorical = to_categorical(train_labels_preprocessed)  \ntest_labels_categorical = to_categorical(test_labels_preprocessed)\n\nprint(train_labels_preprocessed.shape, train_labels_categorical.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T23:32:50.057801Z","iopub.execute_input":"2022-02-13T23:32:50.058438Z","iopub.status.idle":"2022-02-13T23:32:50.065688Z","shell.execute_reply.started":"2022-02-13T23:32:50.058393Z","shell.execute_reply":"2022-02-13T23:32:50.065084Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x=train_images_preprocessed, y=train_labels_categorical, batch_size=6000, epochs=20, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T23:36:52.989633Z","iopub.execute_input":"2022-02-13T23:36:52.989927Z","iopub.status.idle":"2022-02-13T23:36:59.698181Z","shell.execute_reply.started":"2022-02-13T23:36:52.989899Z","shell.execute_reply":"2022-02-13T23:36:59.697285Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"print(history.history['loss'])\nprint(history.history['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-02-13T23:37:43.792741Z","iopub.execute_input":"2022-02-13T23:37:43.793060Z","iopub.status.idle":"2022-02-13T23:37:43.799630Z","shell.execute_reply.started":"2022-02-13T23:37:43.793029Z","shell.execute_reply":"2022-02-13T23:37:43.798482Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"### 테스트 데이터를 기반으로 Label 값 예측\n* model.predict()를 이용하여 label값 예측\n* predict()의 인자로 입력되는 feature array는 학습의 feature array와 shape가 동일해야함. \n* fit() 시 3차원(28x28 2차원 array가 여러개 존재) array 입력 했으므로 predict()도 동일한 3차원 데이터 입력\n* 특히 한건만 predict() 할때도 3차원 데이터여야 함. 이를 위해 expand_dims()로 2차원 image 배열을 3차원으로 변경","metadata":{}},{"cell_type":"code","source":"test_images_preprocessed.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-13T23:57:22.787922Z","iopub.execute_input":"2022-02-13T23:57:22.788244Z","iopub.status.idle":"2022-02-13T23:57:22.794312Z","shell.execute_reply.started":"2022-02-13T23:57:22.788213Z","shell.execute_reply":"2022-02-13T23:57:22.793750Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"pred_proba = model.predict(test_images_preprocessed)\nprint(pred_proba.shape)\npred_proba[0]","metadata":{"execution":{"iopub.status.busy":"2022-02-13T23:58:11.017078Z","iopub.execute_input":"2022-02-13T23:58:11.017361Z","iopub.status.idle":"2022-02-13T23:58:11.431992Z","shell.execute_reply.started":"2022-02-13T23:58:11.017333Z","shell.execute_reply":"2022-02-13T23:58:11.430896Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"np.expand_dims(test_images_preprocessed[0], axis=0).shape","metadata":{"execution":{"iopub.status.busy":"2022-02-14T00:01:05.484481Z","iopub.execute_input":"2022-02-14T00:01:05.484816Z","iopub.status.idle":"2022-02-14T00:01:05.492288Z","shell.execute_reply.started":"2022-02-14T00:01:05.484779Z","shell.execute_reply":"2022-02-14T00:01:05.491313Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"pred_proba = model.predict(np.expand_dims(test_images_preprocessed[0], axis=0))\nprint('softmax output:', pred_proba)\n\npred = np.squeeze(pred_proba)\nprint(pred.shape)\nprint('predicted class value:', np.argmax(pred))\n\npred = pred_proba\nprint(pred.shape)\nprint('predicted class value:', np.argmax(pred))","metadata":{"execution":{"iopub.status.busy":"2022-02-14T00:04:32.072710Z","iopub.execute_input":"2022-02-14T00:04:32.073203Z","iopub.status.idle":"2022-02-14T00:04:32.135184Z","shell.execute_reply.started":"2022-02-14T00:04:32.073171Z","shell.execute_reply":"2022-02-14T00:04:32.134205Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\nprint('target class value:', test_labels[0], 'predicted class value:', pred)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T00:06:08.262479Z","iopub.execute_input":"2022-02-14T00:06:08.263367Z","iopub.status.idle":"2022-02-14T00:06:08.270368Z","shell.execute_reply.started":"2022-02-14T00:06:08.263321Z","shell.execute_reply":"2022-02-14T00:06:08.269673Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"### 테스트 데이터 세트로 모델 성능 검증","metadata":{}},{"cell_type":"code","source":"model.evaluate(test_images, test_labels_categorical, batch_size=100)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T00:07:25.668360Z","iopub.execute_input":"2022-02-14T00:07:25.668797Z","iopub.status.idle":"2022-02-14T00:07:26.088841Z","shell.execute_reply.started":"2022-02-14T00:07:25.668753Z","shell.execute_reply":"2022-02-14T00:07:26.088064Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 검증 데이터 세트를 이용하여 학습 수행. \n* 일반적으로 fit() 수행시 별도의 검증 데이터 세트를 이용하여 학습 시 과적합(Overfitting)이 발생하는지 모니터링\n* fit()을 수행하면 iteration을 반복하기 때문에 중간에 하이퍼파라미터 변경(예: Learning Rate)등의 작업이 어려움. \n* fit() iteration시 여러 작업을 하기 위해 Callback 객체를 가짐. \n* 검증 데이터 세트를 fit() 시 적용하여 과적합이나 더이상 검증 데이터 성능이 좋아 지지 않을 때 Callback을 사용하여 Learning Rate 보정 작업등을 수행 가능","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom tensorflow.keras.datasets import fashion_mnist\n\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n\ndef get_preprocessed_data(images, labels):\n    \n    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n    images = np.array(images/255.0, dtype=np.float32)\n    labels = np.array(labels, dtype=np.float32)\n    \n    return images, labels\n\ntrain_images, train_labels = get_preprocessed_data(train_images, train_labels)\ntest_images, test_labels = get_preprocessed_data(test_images, test_labels)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T00:13:11.117802Z","iopub.execute_input":"2022-02-14T00:13:11.118144Z","iopub.status.idle":"2022-02-14T00:13:17.947784Z","shell.execute_reply.started":"2022-02-14T00:13:11.118057Z","shell.execute_reply":"2022-02-14T00:13:17.947046Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\n\n# 기존 학습 데이터를 다시 학습과 검증 데이터 세트로 분리\ntr_images, val_images, tr_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.15, random_state=2022, shuffle=True)\nprint('train과 validation shape:', tr_images.shape, tr_labels.shape, val_images.shape, val_labels.shape)\n\n# OHE 적용\ntr_oh_labels = to_categorical(tr_labels)\nval_oh_labels = to_categorical(val_labels)\n\nprint('after OHE:', tr_oh_labels.shape, val_oh_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T00:14:51.997520Z","iopub.execute_input":"2022-02-14T00:14:51.997936Z","iopub.status.idle":"2022-02-14T00:14:52.116299Z","shell.execute_reply.started":"2022-02-14T00:14:51.997896Z","shell.execute_reply":"2022-02-14T00:14:52.115021Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\n\nINPUT_SIZE = 28\nmodel = Sequential([\n    Flatten(input_shape=(INPUT_SIZE, INPUT_SIZE)),\n    Dense(100, activation='relu'),\n    Dense(30, activation='relu'),\n    Dense(10, activation='softmax')\n])\n\nmodel.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-02-14T00:18:57.218802Z","iopub.execute_input":"2022-02-14T00:18:57.219088Z","iopub.status.idle":"2022-02-14T00:18:57.256051Z","shell.execute_reply.started":"2022-02-14T00:18:57.219055Z","shell.execute_reply":"2022-02-14T00:18:57.255389Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x=tr_images, y=tr_oh_labels, batch_size=500, validation_data=(val_images, val_oh_labels), \n                    epochs=20, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T00:18:57.579106Z","iopub.execute_input":"2022-02-14T00:18:57.579579Z","iopub.status.idle":"2022-02-14T00:19:08.384796Z","shell.execute_reply.started":"2022-02-14T00:18:57.579545Z","shell.execute_reply":"2022-02-14T00:19:08.384041Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print(history.history['loss'])\nprint(history.history['accuracy'])\nprint(history.history['val_loss'])\nprint(history.history['val_accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-02-14T00:19:36.189839Z","iopub.execute_input":"2022-02-14T00:19:36.190323Z","iopub.status.idle":"2022-02-14T00:19:36.196653Z","shell.execute_reply.started":"2022-02-14T00:19:36.190282Z","shell.execute_reply":"2022-02-14T00:19:36.195661Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.plot(history.history['accuracy'], label='train')\nplt.plot(history.history['val_accuracy'], label='valid')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-02-14T00:19:46.481792Z","iopub.execute_input":"2022-02-14T00:19:46.482396Z","iopub.status.idle":"2022-02-14T00:19:46.720431Z","shell.execute_reply.started":"2022-02-14T00:19:46.482347Z","shell.execute_reply":"2022-02-14T00:19:46.719776Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Functional API\nsequential은 쉽지만 실제 현업에서는 functional로 많이 사용된다.","metadata":{}},{"cell_type":"code","source":"# Sequential Model을 이용하여 Keras 모델 생성 \n\nfrom tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.models import Sequential\n\nINPUT_SIZE = 28\n\n# sequenctial api는 input layer가 별도로 없고, 인자로 input_shape을 줌으로써 인식시킨다.\n# functional api는 input layer를 별도로 만들어줘야 함\nmodel = Sequential([\n    Flatten(input_shape=(INPUT_SIZE, INPUT_SIZE)),\n    Dense(100, activation='relu'),\n    Dense(30, activation='relu'),\n    Dense(10, activation='softmax')\n])\n\nmodel.summary()\n\nmodel1 = Sequential()\nmodel1.add(Flatten(input_shape=(INPUT_SIZE, INPUT_SIZE)))\nmodel1.add(Dense(100, activation='relu'))\nmodel1.add(Dense(30, activation='relu'))\nmodel1.add(Dense(10, activation='softmax'))\n\nmodel1.summary()\n","metadata":{"execution":{"iopub.status.busy":"2022-02-14T00:22:39.727433Z","iopub.execute_input":"2022-02-14T00:22:39.728319Z","iopub.status.idle":"2022-02-14T00:22:39.988866Z","shell.execute_reply.started":"2022-02-14T00:22:39.728278Z","shell.execute_reply":"2022-02-14T00:22:39.988159Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Functional Api로 모델 만들기\n\nfrom tensorflow.keras.layers import Input, Flatten, Dense\nfrom tensorflow.keras.models import Model\n\n# sequenctial api는 input layer가 별도로 없고, 인자로 input_shape을 줌으로써 인식시킨다.\n# functional api는 input layer를 별도로 만들어줘야 함\ninput_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE))\nx = Flatten()(input_tensor)\nx = Dense(100, activation='relu')(x)\nx = Dense(30, activation='relu')(x)\noutput = Dense(10, activation='softmax')(x)\n\nmodel = Model(inputs=input_tensor, outputs=output)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-14T00:33:06.853131Z","iopub.execute_input":"2022-02-14T00:33:06.853878Z","iopub.status.idle":"2022-02-14T00:33:06.890893Z","shell.execute_reply.started":"2022-02-14T00:33:06.853827Z","shell.execute_reply":"2022-02-14T00:33:06.890214Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### Custom한 Dense Layer 생성하기","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Layer, Input\nfrom tensorflow.keras.models import Model\nimport tensorflow as tf\n\nclass CustomDense(tf.keras.layers.Layer):\n    # CustomDense 객체 생성시 입력되는 초기화 parameter 처리\n    def __init__(self, units=32):\n        super(CustomDense, self).__init__()\n        self.units = units\n\n    def build(self, input_shape):\n        self.w = self.add_weight(\n            shape=(input_shape[-1], self.units),\n            initializer=\"random_normal\",\n            trainable=True,\n        )\n        self.b = self.add_weight(\n            shape=(self.units,), initializer=\"random_normal\", trainable=True\n        )\n        \n    # CustomDense 객체에 callable로 입력된 입력 데이터 처리. \n    def call(self, inputs):\n        return tf.matmul(inputs, self.w) + self.b\n\n# input 값을 4개의 원소를 가지는 1차원으로 생성. \ninputs = Input((4,))\n# 10개의 unit을 가지는 CustomDense 객체를 생성 후 callable로 inputs값 입력 \noutputs = CustomDense(10)(inputs)\n\n# inputs와 outputs로 model 생성. \nmodel = Model(inputs, outputs)\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2022-02-14T00:55:02.742116Z","iopub.execute_input":"2022-02-14T00:55:02.742841Z","iopub.status.idle":"2022-02-14T00:55:02.798710Z","shell.execute_reply.started":"2022-02-14T00:55:02.742803Z","shell.execute_reply":"2022-02-14T00:55:02.797879Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"### Functional API는 객체 생성 부분과 Callable 인자 입력 부분을 별도로 수행해도 무방. ","metadata":{}},{"cell_type":"code","source":"inputs = Input((4,))\n# 10개의 unit을 가지는 CustomDense 객체를 생성 후 callable로 inputs값 입력 \nmy_layer = CustomDense(10)\noutputs = my_layer(inputs)\n\n# inputs와 outputs로 model 생성. \nmodel = Model(inputs, outputs)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-14T00:56:42.890585Z","iopub.execute_input":"2022-02-14T00:56:42.891258Z","iopub.status.idle":"2022-02-14T00:56:42.910963Z","shell.execute_reply.started":"2022-02-14T00:56:42.891219Z","shell.execute_reply":"2022-02-14T00:56:42.910293Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"### Sequential Model 생성은 단지 Functional API Layer들을 iteration 하면서 연결한 것을 model로 만든 것임","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\n\nmodel = Sequential([Input((4,)),\n                   CustomDense(10),\n                   CustomDense(8), \n                   tf.keras.layers.ReLU()])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-14T00:56:51.493766Z","iopub.execute_input":"2022-02-14T00:56:51.494594Z","iopub.status.idle":"2022-02-14T00:56:51.524745Z","shell.execute_reply.started":"2022-02-14T00:56:51.494558Z","shell.execute_reply":"2022-02-14T00:56:51.524023Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"### Sequential Model을 Functional 객체를 For loop 반복 호출하여 작성.","metadata":{}},{"cell_type":"code","source":"layers_list = [Input((4,)), CustomDense(10), CustomDense(8), tf.keras.layers.ReLU()]\n\nfor index, layer in enumerate(layers_list):\n        print(index, layer)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T00:57:20.559382Z","iopub.execute_input":"2022-02-14T00:57:20.559646Z","iopub.status.idle":"2022-02-14T00:57:20.570328Z","shell.execute_reply.started":"2022-02-14T00:57:20.559616Z","shell.execute_reply":"2022-02-14T00:57:20.569520Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"layers_list = [Input((4,)), CustomDense(10), CustomDense(8), tf.keras.layers.ReLU()]\n\ninputs = None\ncallable_inputs = None\noutputs = None\n# layers_list에 있는 Functional 객체를 iteration 수행하면서 적용. \nfor index, layer in enumerate(layers_list):\n    # layers_list의 첫번째 인자는 Input 간주. \n    if index == 0:\n        inputs = layer\n        callable_inputs = layer\n    # Functional 객체에 callable 인자로 callable_inputs를 입력하고 반환 결과 값을 다시 callable_inputs로 할당.     \n    else: \n        callable_inputs = layer(callable_inputs)\n    \noutputs = callable_inputs\nmodel = Model(inputs, outputs)\nmodel.summary()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 앞에서 생성한 로직들을 함수화 \n* Functional API로 모델 만들기\n* pixel값 1 ~ 255를 0 ~ 1사이값 Float 32로 만들기\n* One Hot Encoding Label에 적용하기\n* 학습과 검증 데이터로 나누기.\n* compile, 학습/예측/평가","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Layer, Input, Dense, Flatten\nfrom tensorflow.keras.models import Model\nimport tensorflow as tf\n\nINPUT_SIZE = 28\n\ndef create_model():\n    input_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE))\n    x = Flatten()(input_tensor)\n    x = Dense(100, activation='relu')(x)\n    x = Dense(30, activation='relu')(x)\n    output = Dense(10, activation='softmax')(x)\n    \n    model = Model(inputs=input_tensor, outputs=output)\n    return model\n\nmodel = create_model()\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2022-02-14T01:31:31.087874Z","iopub.execute_input":"2022-02-14T01:31:31.088481Z","iopub.status.idle":"2022-02-14T01:31:31.134365Z","shell.execute_reply.started":"2022-02-14T01:31:31.088443Z","shell.execute_reply":"2022-02-14T01:31:31.133651Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\n# 0 ~ 1사이값의 float32로 변경하는 함수\ndef get_preprocessed_data(images, labels):\n    \n    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n    images = np.array(images/255.0, dtype=np.float32)\n    labels = np.array(labels, dtype=np.float32)\n    \n    return images, labels\n\n# 0 ~ 1사이값 float32로 변경하는 함수 호출 한 뒤 OHE 적용 \ndef get_preprocessed_ohe(images, labels):\n    images, labels = get_preprocessed_data(images, labels)\n    # OHE 적용 \n    oh_labels = to_categorical(labels)\n    return images, oh_labels\n\n# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \ndef get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용. \n    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n    \n    # 학습 데이터를 검증 데이터 세트로 다시 분리\n    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n    \n    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels ) \n","metadata":{"execution":{"iopub.status.busy":"2022-02-14T01:31:31.262444Z","iopub.execute_input":"2022-02-14T01:31:31.262653Z","iopub.status.idle":"2022-02-14T01:31:31.274897Z","shell.execute_reply.started":"2022-02-14T01:31:31.262628Z","shell.execute_reply":"2022-02-14T01:31:31.273983Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.datasets import fashion_mnist\n# Fashion MNIST 데이터 재 로딩 및 전처리 적용하여 학습/검증/데이터 세트 생성. \n\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\nprint(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n(tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n    get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\nprint(tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_labels.shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-14T01:31:31.489205Z","iopub.execute_input":"2022-02-14T01:31:31.489429Z","iopub.status.idle":"2022-02-14T01:31:32.188014Z","shell.execute_reply.started":"2022-02-14T01:31:31.489404Z","shell.execute_reply":"2022-02-14T01:31:32.187253Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n\n# Model 생성 및 optimizer, loss, metric 적용\nmodel = create_model()\nmodel.summary()\n\nmodel.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2022-02-14T01:31:32.193349Z","iopub.execute_input":"2022-02-14T01:31:32.195610Z","iopub.status.idle":"2022-02-14T01:31:32.267914Z","shell.execute_reply.started":"2022-02-14T01:31:32.195565Z","shell.execute_reply":"2022-02-14T01:31:32.266421Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# 학습 수행. \nhistory = model.fit(x=tr_images, y=tr_oh_labels, batch_size=1000, epochs=20, validation_data=(val_images, val_oh_labels))\n","metadata":{"execution":{"iopub.status.busy":"2022-02-14T01:31:32.314363Z","iopub.execute_input":"2022-02-14T01:31:32.314603Z","iopub.status.idle":"2022-02-14T01:31:37.305360Z","shell.execute_reply.started":"2022-02-14T01:31:32.314571Z","shell.execute_reply":"2022-02-14T01:31:37.304628Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\ndef show_history(history):\n    plt.plot(history.history['accuracy'], label='train')\n    plt.plot(history.history['val_accuracy'], label='valid')\n    plt.legend()\n    \nshow_history(history)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T01:31:37.308589Z","iopub.execute_input":"2022-02-14T01:31:37.308806Z","iopub.status.idle":"2022-02-14T01:31:37.516378Z","shell.execute_reply.started":"2022-02-14T01:31:37.308782Z","shell.execute_reply":"2022-02-14T01:31:37.515700Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# 테스트 데이터 세트로 모델 성능 검증\nmodel.evaluate(test_images, test_oh_labels, batch_size=256, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T01:32:09.684381Z","iopub.execute_input":"2022-02-14T01:32:09.684641Z","iopub.status.idle":"2022-02-14T01:32:10.003532Z","shell.execute_reply.started":"2022-02-14T01:32:09.684613Z","shell.execute_reply":"2022-02-14T01:32:10.002837Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"## Callback ","metadata":{}},{"cell_type":"markdown","source":"#### ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n* 특정 조건에 맞춰서 모델을 파일로 저장\n* filepath: filepath는 (on_epoch_end에서 전달되는) epoch의 값과 logs의 키로 채워진 이름 형식 옵션을 가질 수 있음.\n예를 들어 filepath가 weights.{epoch:02d}-{val_loss:.2f}.hdf5라면, 파일 이름에 세대 번호와 검증 손실을 넣어 모델의 체크포인트가 저장 \n* monitor: 모니터할 지표(loss 또는 평가 지표) \n* save_best_only: 가장 좋은 성능을 나타내는 모델만 저장할 여부\n* save_weights_only: Weights만 저장할 지 여부 => 웬만하면 이거만 True하고 나중에 load weights 해주는게 나음\n* mode: {auto, min, max} 중 하나. monitor 지표가 감소해야 좋을 경우 min, 증가해야 좋을 경우 max, auto는 monitor 이름에서 자동으로 유추. ","metadata":{}},{"cell_type":"code","source":"!pwd","metadata":{"execution":{"iopub.status.busy":"2022-02-14T01:43:12.186467Z","iopub.execute_input":"2022-02-14T01:43:12.186727Z","iopub.status.idle":"2022-02-14T01:43:12.883944Z","shell.execute_reply.started":"2022-02-14T01:43:12.186698Z","shell.execute_reply":"2022-02-14T01:43:12.883072Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\n\nmodel = create_model()\nmodel.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nmcp_cb = ModelCheckpoint(filepath='/kaggle/working/weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', \n                         save_best_only=True, save_weights_only=True, mode='min', period=3, verbose=1)\nhistory = model.fit(x=tr_images, y=tr_oh_labels, batch_size=1000, epochs=10, validation_data=(val_images, val_oh_labels),\n                   callbacks=[mcp_cb])","metadata":{"execution":{"iopub.status.busy":"2022-02-14T01:54:43.268829Z","iopub.execute_input":"2022-02-14T01:54:43.269588Z","iopub.status.idle":"2022-02-14T01:54:46.439324Z","shell.execute_reply.started":"2022-02-14T01:54:43.269549Z","shell.execute_reply":"2022-02-14T01:54:46.438468Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"!ls -lia\n# !rm -rf weight*\n# !ls -lia\n","metadata":{"execution":{"iopub.status.busy":"2022-02-14T01:54:46.441233Z","iopub.execute_input":"2022-02-14T01:54:46.441639Z","iopub.status.idle":"2022-02-14T01:54:47.189643Z","shell.execute_reply.started":"2022-02-14T01:54:46.441595Z","shell.execute_reply":"2022-02-14T01:54:47.188837Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"#### ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n* 특정 epochs 횟수동안 성능이 개선 되지 않을 시 Learning rate를 동적으로 감소 시킴 \n* monitor: 모니터할 지표(loss 또는 평가 지표) \n* factor: 학습 속도를 줄일 인수. new_lr = lr * factor \n* patience: Learing Rate를 줄이기 전에 monitor할 epochs 횟수. \n* mode: {auto, min, max} 중 하나. monitor 지표가 감소해야 좋을 경우 min, 증가해야 좋을 경우 max, auto는 monitor 이름에서 유추. ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ReduceLROnPlateau\n\nmodel = create_model()\nmodel.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nrlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, mode='min', verbose=1)\nhistory = model.fit(x=tr_images, y=tr_oh_labels, batch_size=1000, epochs=30, validation_data=(val_images, val_oh_labels),\n                   callbacks=[rlr_cb])","metadata":{"execution":{"iopub.status.busy":"2022-02-14T01:58:25.309143Z","iopub.execute_input":"2022-02-14T01:58:25.309645Z","iopub.status.idle":"2022-02-14T01:58:36.141032Z","shell.execute_reply.started":"2022-02-14T01:58:25.309604Z","shell.execute_reply":"2022-02-14T01:58:36.140262Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"#### EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n* 특정 epochs 동안 성능이 개선되지 않을 시 학습을 조기에 중단\n* monitor: 모니터할 지표(loss 또는 평가 지표) \n* patience: Early Stopping 적용 전에 monitor할 epochs 횟수. \n* mode: {auto, min, max} 중 하나. monitor 지표가 감소해야 좋을 경우 min, 증가해야 좋을 경우 max, auto는 monitor 이름에서 유추. ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n\nmodel = create_model()\nmodel.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nely_cb = EarlyStopping(monitor='val_loss', patience=3, mode='min', verbose=1)\nhistory = model.fit(x=tr_images, y=tr_oh_labels, batch_size=128, epochs=30, validation_data=(val_images, val_oh_labels),\n                   callbacks=[ely_cb])","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:00:28.118500Z","iopub.execute_input":"2022-02-14T02:00:28.118814Z","iopub.status.idle":"2022-02-14T02:00:41.979573Z","shell.execute_reply.started":"2022-02-14T02:00:28.118783Z","shell.execute_reply":"2022-02-14T02:00:41.978868Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"!rm weigh*","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:01:00.157460Z","iopub.execute_input":"2022-02-14T02:01:00.157720Z","iopub.status.idle":"2022-02-14T02:01:00.877644Z","shell.execute_reply.started":"2022-02-14T02:01:00.157692Z","shell.execute_reply":"2022-02-14T02:01:00.876710Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n\nmodel = create_model()\nmodel.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nmcp_cb = ModelCheckpoint(filepath='/kaggle/working/weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', \n                         save_best_only=True, save_weights_only=True, mode='min', period=1, verbose=0)\nrlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=5, mode='min', verbose=1)\nely_cb = EarlyStopping(monitor='val_loss', patience=7, mode='min', verbose=1)\n\nhistory = model.fit(x=tr_images, y=tr_oh_labels, batch_size=500, epochs=40, validation_data=(val_images, val_oh_labels),\n                   callbacks=[mcp_cb, rlr_cb, ely_cb])","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:01:33.068454Z","iopub.execute_input":"2022-02-14T02:01:33.068739Z","iopub.status.idle":"2022-02-14T02:02:04.689617Z","shell.execute_reply.started":"2022-02-14T02:01:33.068711Z","shell.execute_reply":"2022-02-14T02:02:04.688917Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"!ls -lia","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:04:50.034898Z","iopub.execute_input":"2022-02-14T02:04:50.035598Z","iopub.status.idle":"2022-02-14T02:04:50.771748Z","shell.execute_reply.started":"2022-02-14T02:04:50.035560Z","shell.execute_reply":"2022-02-14T02:04:50.770958Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}